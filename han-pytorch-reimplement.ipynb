{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-05T16:18:10.161278Z","iopub.status.busy":"2024-05-05T16:18:10.160472Z","iopub.status.idle":"2024-05-05T16:20:50.561421Z","shell.execute_reply":"2024-05-05T16:20:50.560323Z","shell.execute_reply.started":"2024-05-05T16:18:10.161234Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-05-05 16:18:11--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2024-05-05 16:18:11--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2024-05-05 16:18:11--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: 'glove.6B.zip'\n","\n","glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n","\n","2024-05-05 16:20:50 (5.18 MB/s) - 'glove.6B.zip' saved [862182613/862182613]\n","\n"]}],"source":["!wget http://nlp.stanford.edu/data/glove.6B.zip"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:20:50.563590Z","iopub.status.busy":"2024-05-05T16:20:50.563294Z","iopub.status.idle":"2024-05-05T16:21:11.317481Z","shell.execute_reply":"2024-05-05T16:21:11.316254Z","shell.execute_reply.started":"2024-05-05T16:20:50.563560Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  glove.6B.zip\n","  inflating: glove.6B.50d.txt        \n","  inflating: glove.6B.100d.txt       \n","  inflating: glove.6B.200d.txt       \n","  inflating: glove.6B.300d.txt       \n"]}],"source":["!unzip glove*.zip"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:11.319928Z","iopub.status.busy":"2024-05-05T16:21:11.319127Z","iopub.status.idle":"2024-05-05T16:21:17.306316Z","shell.execute_reply":"2024-05-05T16:21:17.305545Z","shell.execute_reply.started":"2024-05-05T16:21:11.319883Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from sklearn.datasets import fetch_20newsgroups"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:17.309517Z","iopub.status.busy":"2024-05-05T16:21:17.308962Z","iopub.status.idle":"2024-05-05T16:21:17.323773Z","shell.execute_reply":"2024-05-05T16:21:17.322842Z","shell.execute_reply.started":"2024-05-05T16:21:17.309483Z"},"trusted":true},"outputs":[],"source":["class News20Dataset(Dataset):\n","  def __init__(self, word_map_path, max_sent_length=150, max_doc_length=40, is_train=True):\n","    self.max_sent_length = max_sent_length\n","    self.max_doc_length = max_doc_length\n","    self.split = 'train' if is_train else 'test'\n","\n","    self.data = fetch_20newsgroups(\n","        subset=self.split,\n","        categories=['sci.crypt', 'sci.electronics', 'sci.med', 'sci.space'],\n","        shuffle=False,\n","        remove=('headers', 'footers', 'quotes')\n","    )\n","\n","    # Load vocabulary from word map file\n","    self.vocab = pd.read_csv(\n","        filepath_or_buffer=word_map_path,\n","        header=None,\n","        sep=' ',\n","        quoting=csv.QUOTE_NONE,\n","        usecols=[0]\n","    ).values[:50000]\n","\n","    # Create vocabulary list\n","    self.vocab = ['', ''] + [word[0] for word in self.vocab]\n","\n","  def transform(self, text):\n","    doc = [\n","        [self.vocab.index(word) if word in self.vocab else 1 for word in word_tokenize(text=sent)]\n","        for sent in sent_tokenize(text=text)\n","    ]\n","    doc = [sent[:self.max_sent_length] for sent in doc][:self.max_doc_length]\n","    num_sents = min(len(doc), self.max_doc_length)\n","    if num_sents == 0:\n","      return None, -1, None\n","\n","    num_words = [min(len(sent), self.max_sent_length) for sent in doc][:self.max_doc_length]\n","\n","    return doc, num_sents, num_words\n","\n","  def __getitem__(self, i):\n","    label = self.data['target'][i]\n","    text = self.data['data'][i]\n","\n","    doc, num_sents, num_words = self.transform(text)\n","\n","    if num_sents == -1:\n","      return None\n","\n","    return doc, label, num_sents, num_words\n","\n","  def __len__(self):\n","    return len(self.data['data'])\n","\n","  @property\n","  def vocab_size(self):\n","    return len(self.vocab)\n","\n","  @property\n","  def num_classes(self):\n","    return 4\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:17.325556Z","iopub.status.busy":"2024-05-05T16:21:17.325013Z","iopub.status.idle":"2024-05-05T16:21:18.641954Z","shell.execute_reply":"2024-05-05T16:21:18.640785Z","shell.execute_reply.started":"2024-05-05T16:21:17.325524Z"},"trusted":true},"outputs":[],"source":["def collate_fn(batch):\n","  batch = filter(lambda x: x is not None, batch)\n","  docs, labels, doc_lengths, sent_lengths = list(zip(*batch))\n","\n","  bsz = len(labels)\n","  batch_max_doc_length = max(doc_lengths)\n","  batch_max_sent_length = max([max(sl) if sl else 0 for sl in sent_lengths])\n","\n","  # Initialize tensors for documents and sentence lengths\n","  docs_tensor = torch.zeros([bsz, batch_max_doc_length, batch_max_sent_length]).long()\n","  sent_lengths_tensor = torch.zeros([bsz, batch_max_doc_length]).long()\n","\n","  # Fill in tensors with data from batch\n","  for doc_idx, doc in enumerate(docs):\n","    doc_length = doc_lengths[doc_idx]\n","    sent_lengths_tensor[doc_idx, :doc_length] = torch.LongTensor(sent_lengths[doc_idx])\n","    for sent_idx, sent in enumerate(doc):\n","      sent_length = sent_lengths[doc_idx][sent_idx]\n","      docs_tensor[doc_idx, sent_idx, :sent_length] = torch.LongTensor(sent)\n","\n","  return docs_tensor, torch.LongTensor(labels), torch.LongTensor(doc_lengths), sent_lengths_tensor"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:18.644171Z","iopub.status.busy":"2024-05-05T16:21:18.643479Z","iopub.status.idle":"2024-05-05T16:21:18.657000Z","shell.execute_reply":"2024-05-05T16:21:18.656090Z","shell.execute_reply.started":"2024-05-05T16:21:18.644135Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","from torch.utils.data.sampler import RandomSampler"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:18.659109Z","iopub.status.busy":"2024-05-05T16:21:18.658246Z","iopub.status.idle":"2024-05-05T16:21:18.838506Z","shell.execute_reply":"2024-05-05T16:21:18.837538Z","shell.execute_reply.started":"2024-05-05T16:21:18.659082Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:18.839936Z","iopub.status.busy":"2024-05-05T16:21:18.839638Z","iopub.status.idle":"2024-05-05T16:21:18.846040Z","shell.execute_reply":"2024-05-05T16:21:18.845142Z","shell.execute_reply.started":"2024-05-05T16:21:18.839911Z"},"trusted":true},"outputs":[],"source":["class MyDataLoader(DataLoader):\n","  def __init__(self, dataset, batch_size):\n","    self.n_samples = len(dataset)\n","    self.sampler = RandomSampler(dataset)\n","\n","    self.init_kwargs = {\n","        'dataset': dataset,\n","        'batch_size': batch_size,\n","        'pin_memory': True,  # Pin memory for faster GPU transfers if available\n","        'collate_fn': collate_fn,  # Collate function for batching data\n","        'shuffle': False  # Disable shuffling to maintain consistency during evaluation\n","    }\n","\n","    # Initialize DataLoader using superclass constructor\n","    super().__init__(sampler=self.sampler, **self.init_kwargs)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:18.847461Z","iopub.status.busy":"2024-05-05T16:21:18.847198Z","iopub.status.idle":"2024-05-05T16:21:20.432163Z","shell.execute_reply":"2024-05-05T16:21:20.431212Z","shell.execute_reply.started":"2024-05-05T16:21:18.847432Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import csv"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:20.437021Z","iopub.status.busy":"2024-05-05T16:21:20.436355Z","iopub.status.idle":"2024-05-05T16:21:36.393115Z","shell.execute_reply":"2024-05-05T16:21:36.392338Z","shell.execute_reply.started":"2024-05-05T16:21:20.436981Z"},"trusted":true},"outputs":[],"source":["dataset = News20Dataset('glove.6B.100d.txt', is_train=True)\n","data_loader = MyDataLoader(dataset, 64)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:36.394516Z","iopub.status.busy":"2024-05-05T16:21:36.394228Z","iopub.status.idle":"2024-05-05T16:21:36.399161Z","shell.execute_reply":"2024-05-05T16:21:36.398213Z","shell.execute_reply.started":"2024-05-05T16:21:36.394491Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, PackedSequence"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:36.400546Z","iopub.status.busy":"2024-05-05T16:21:36.400273Z","iopub.status.idle":"2024-05-05T16:21:36.416209Z","shell.execute_reply":"2024-05-05T16:21:36.415250Z","shell.execute_reply.started":"2024-05-05T16:21:36.400524Z"},"trusted":true},"outputs":[],"source":["class WordAttention(nn.Module):\n","  def __init__(self, vocab_size, embed_dim, gru_hidden_dim, gru_num_layers, att_dim, use_layer_norm, dropout):\n","    super(WordAttention, self).__init__()\n","    self.embeddings = nn.Embedding(vocab_size, embed_dim)\n","    self.gru = nn.GRU(\n","        embed_dim,\n","        gru_hidden_dim,\n","        num_layers=gru_num_layers,\n","        batch_first=True,\n","        bidirectional=True,\n","        dropout=dropout\n","    )\n","    self.use_layer_norm = use_layer_norm\n","    if use_layer_norm:\n","      self.layer_norm = nn.LayerNorm(2 * gru_hidden_dim, elementwise_affine=True)\n","    self.dropout = nn.Dropout(dropout)\n","\n","    self.attention = nn.Linear(2 * gru_hidden_dim, att_dim)\n","\n","    self.context_vector = nn.Linear(att_dim, 1, bias=False)\n","\n","  def init_embeddings(self, embeddings):\n","    self.embeddings.weight = nn.Parameter(embeddings)\n","\n","  def freeze_embeddings(self, freeze=False):\n","    self.embeddings.weight.requires_grad = not freeze\n","\n","  def forward(self, sents, sent_lengths):\n","    # Sort sentences by length for efficient processing\n","    sent_lengths, sent_perm_idx = sent_lengths.sort(dim=0, descending=True)\n","    sents = sents[sent_perm_idx]\n","\n","    # Pass sentences through embedding layer and apply dropout\n","    sents = self.embeddings(sents)\n","    sents = self.dropout(sents)\n","\n","    # Pack sequences for dynamic sequence handling\n","    packed_words = pack_padded_sequence(sents, lengths=sent_lengths.tolist(), batch_first=True)\n","\n","    valid_bsz = packed_words.batch_sizes\n","\n","    # Pass packed sequences through bidirectional GRU layer\n","    packed_words, _ = self.gru(packed_words)\n","\n","    # Optionally apply layer normalization\n","    if self.use_layer_norm:\n","      normed_words = self.layer_norm(packed_words.data)\n","    else:\n","      normed_words = packed_words\n","\n","    # Compute attention weights\n","    att = torch.tanh(self.attention(normed_words.data))\n","    att = self.context_vector(att).squeeze(1)\n","    val = att.max()\n","    att = torch.exp(att - val)\n","    att, _ = pad_packed_sequence(PackedSequence(att, valid_bsz), batch_first=True)\n","    att_weights = att / torch.sum(att, dim = 1, keepdim=True)\n","\n","    # Apply attention to GRU outputs and aggregate attended representations\n","    sents, _ = pad_packed_sequence(packed_words, batch_first=True)\n","    sents = sents * att_weights.unsqueeze(2)\n","    sents = sents.sum(dim=1)\n","\n","    # Restore original order of sentences\n","    _, sent_unperm_idx = sent_perm_idx.sort(dim=0, descending=False)\n","    sents = sents[sent_unperm_idx]\n","    att_weights = att_weights[sent_unperm_idx]\n","\n","    return sents, att_weights\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:36.417673Z","iopub.status.busy":"2024-05-05T16:21:36.417408Z","iopub.status.idle":"2024-05-05T16:21:36.433989Z","shell.execute_reply":"2024-05-05T16:21:36.433162Z","shell.execute_reply.started":"2024-05-05T16:21:36.417645Z"},"trusted":true},"outputs":[],"source":["class SentenceAttention(nn.Module):\n","  def __init__(self, vocab_size, embed_dim, word_gru_hidden_dim, sent_gru_hidden_dim,\n","              word_gru_num_layers, sent_gru_num_layers, word_att_dim, sent_att_dim, use_layer_norm, dropout):\n","      super(SentenceAttention, self).__init__()\n","\n","      # Word-level attention module\n","      self.word_attention = WordAttention(vocab_size, embed_dim, word_gru_hidden_dim, word_gru_num_layers,\n","                                          word_att_dim, use_layer_norm, dropout)\n","\n","      # Bidirectional sentence-level GRU\n","      self.gru = nn.GRU(2 * word_gru_hidden_dim, sent_gru_hidden_dim, num_layers=sent_gru_num_layers,\n","                        batch_first=True, bidirectional=True, dropout=dropout)\n","\n","      # Optionally apply layer normalization\n","      self.use_layer_norm = use_layer_norm\n","      if use_layer_norm:\n","          self.layer_norm = nn.LayerNorm(2 * sent_gru_hidden_dim, elementwise_affine=True)\n","      self.dropout = nn.Dropout(dropout)\n","\n","      # Sentence-level attention\n","      self.sent_attention = nn.Linear(2 * sent_gru_hidden_dim, sent_att_dim)\n","\n","      # Sentence context vector u_s to take dot product with\n","      self.sentence_context_vector = nn.Linear(sent_att_dim, 1, bias=False)\n","\n","  def forward(self, docs, doc_lengths, sent_lengths):\n","      # Sort documents by decreasing order in length\n","      doc_lengths, doc_perm_idx = doc_lengths.sort(dim=0, descending=True)\n","      docs = docs[doc_perm_idx]\n","      sent_lengths = sent_lengths[doc_perm_idx]\n","\n","      # Make a long batch of sentences by removing pad-sentences\n","      packed_sents = pack_padded_sequence(docs, lengths=doc_lengths.tolist(), batch_first=True)\n","\n","      # effective batch size at each timestep\n","      valid_bsz = packed_sents.batch_sizes\n","\n","      # Make a long batch of sentence lengths by removing pad-sentences\n","      packed_sent_lengths = pack_padded_sequence(sent_lengths, lengths=doc_lengths.tolist(), batch_first=True)\n","\n","      # Word attention module\n","      sents, word_att_weights = self.word_attention(packed_sents.data, packed_sent_lengths.data)\n","\n","      # Optionally apply dropout\n","      sents = self.dropout(sents)\n","\n","      # Sentence-level GRU over sentence embeddings\n","      packed_sents, _ = self.gru(PackedSequence(sents, valid_bsz))\n","\n","      # Optionally apply layer normalization\n","      if self.use_layer_norm:\n","          normed_sents = self.layer_norm(packed_sents.data)\n","      else:\n","          normed_sents = packed_sents\n","\n","      # Sentence attention\n","      att = torch.tanh(self.sent_attention(normed_sents))\n","      att = self.sentence_context_vector(att).squeeze(1)\n","\n","      # Normalize attention weights\n","      val = att.max()\n","      att = torch.exp(att - val)\n","      att, _ = pad_packed_sequence(PackedSequence(att, valid_bsz), batch_first=True)\n","      sent_att_weights = att / torch.sum(att, dim=1, keepdim=True)\n","\n","      # Restore as documents by repadding\n","      docs, _ = pad_packed_sequence(packed_sents, batch_first=True)\n","\n","      # Compute document vectors\n","      docs = docs * sent_att_weights.unsqueeze(2)\n","      docs = docs.sum(dim=1)\n","\n","      # Restore as documents by repadding\n","      word_att_weights, _ = pad_packed_sequence(PackedSequence(word_att_weights, valid_bsz), batch_first=True)\n","\n","      # Restore the original order of documents (undo the first sorting)\n","      _, doc_unperm_idx = doc_perm_idx.sort(dim=0, descending=False)\n","      docs = docs[doc_unperm_idx]\n","      word_att_weights = word_att_weights[doc_unperm_idx]\n","      sent_att_weights = sent_att_weights[doc_unperm_idx]\n","\n","      return docs, word_att_weights, sent_att_weights"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:36.435253Z","iopub.status.busy":"2024-05-05T16:21:36.434970Z","iopub.status.idle":"2024-05-05T16:21:36.449787Z","shell.execute_reply":"2024-05-05T16:21:36.449085Z","shell.execute_reply.started":"2024-05-05T16:21:36.435226Z"},"trusted":true},"outputs":[],"source":["class HierarchicalAttentionNetwork(nn.Module):\n","  def __init__(self,\n","               num_classes,\n","               vocab_size,\n","               embed_dim,\n","               word_gru_hidden_dim,\n","               sent_gru_hidden_dim,\n","               word_gru_num_layers,\n","               sent_gru_num_layers,\n","               word_att_dim,\n","               sent_att_dim,\n","               use_layer_norm,\n","               dropout):\n","    super(HierarchicalAttentionNetwork, self).__init__()\n","    self.sent_attention = SentenceAttention(\n","        vocab_size,\n","        embed_dim,\n","        word_gru_hidden_dim,\n","        sent_gru_hidden_dim,\n","        word_gru_num_layers,\n","        sent_gru_num_layers,\n","        word_att_dim,\n","        sent_att_dim,\n","        use_layer_norm,\n","        dropout\n","    )\n","\n","    # Fully connected layer for classification\n","    self.fc = nn.Linear(2 * sent_gru_hidden_dim, num_classes)\n","\n","    self.use_layer_norm = use_layer_norm\n","    self.dropout = dropout\n","\n","  def forward(self, docs, doc_lengths, sent_lengths):\n","    # Compute document embeddings and attention weights\n","    doc_embed, word_att_weights, sent_att_weights = self.sent_attention(docs, doc_lengths, sent_lengths)\n","\n","    # Pass document embeddings through the fully connected layer for classification\n","    scores = self.fc(doc_embed)\n","\n","    return scores, word_att_weights, sent_att_weights\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:36.451161Z","iopub.status.busy":"2024-05-05T16:21:36.450898Z","iopub.status.idle":"2024-05-05T16:21:36.465391Z","shell.execute_reply":"2024-05-05T16:21:36.464665Z","shell.execute_reply.started":"2024-05-05T16:21:36.451133Z"},"trusted":true},"outputs":[],"source":["class MetricTracker(object):\n","  def __init__(self):\n","    self.reset()\n","\n","  def reset(self):\n","    self.val = 0\n","    self.avg = 0\n","    self.sum = 0\n","    self.count = 0\n","\n","  def update(self, summed_val, n=1):\n","    # Compute average value for the current batch or epoch\n","    self.val = summed_val / n\n","    # Update sum of all values encountered so far\n","    self.sum += summed_val\n","    # Increment count of total number of samples seen\n","    self.count += n\n","    # Compute running average of all values encountered so far\n","    self.avg = self.sum / self.count\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:36.466528Z","iopub.status.busy":"2024-05-05T16:21:36.466278Z","iopub.status.idle":"2024-05-05T16:21:36.480692Z","shell.execute_reply":"2024-05-05T16:21:36.479941Z","shell.execute_reply.started":"2024-05-05T16:21:36.466506Z"},"trusted":true},"outputs":[],"source":["class Evaluation:\n","  def __init__(self, config, model):\n","    self.config = config\n","    self.model = model\n","    self.device = next(self.model.parameters()).device\n","\n","    # Initialize dataset and data loader for evaluation\n","    self.dataset = News20Dataset(config['vocab_path'], is_train=False)\n","    self.dataloader = torch.utils.data.DataLoader(self.dataset, batch_size=config['batch_size'], shuffle=False, collate_fn=collate_fn)\n","\n","    # Initialize accuracy tracker\n","    self.accs = MetricTracker()\n","    self.best_acc = 0\n","\n","  def eval(self):\n","    # Set model to evaluation mode\n","    self.model.eval()\n","    # Disable gradient calculation\n","    with torch.no_grad():\n","      # Reset accuracy tracker\n","      self.accs.reset()\n","\n","      # Iterate over batches of data\n","      for (docs, labels, doc_lengths, sent_lengths) in self.dataloader:\n","        batch_size = labels.size(0)\n","\n","        # Move data to device\n","        docs = docs.to(self.device)\n","        sent_lengths = sent_lengths.to(self.device)\n","        labels = labels.to(self.device)\n","        doc_lengths = doc_lengths.to(self.device)\n","\n","        # Forward pass through the model\n","        scores, word_at_weights, sentence_att_weights = self.model(docs, doc_lengths, sent_lengths)\n","\n","        # Compute predictions\n","        predictions = scores.max(dim=1)[1]\n","\n","        # Calculate accuracy for the batch\n","        correct_predictions = torch.eq(predictions, labels).sum().item()\n","        acc = correct_predictions\n","\n","        # Update accuracy tracker\n","        self.accs.update(acc, batch_size)\n","\n","      # Update best accuracy if current average accuracy is higher\n","      self.best_acc = max(self.best_acc, self.accs.avg)\n","\n","      # Print test average accuracy\n","      print('Test Average Accuracy: {acc.avg:.4f}'.format(acc=self.accs))"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:36.482581Z","iopub.status.busy":"2024-05-05T16:21:36.482200Z","iopub.status.idle":"2024-05-05T16:21:36.498840Z","shell.execute_reply":"2024-05-05T16:21:36.498007Z","shell.execute_reply.started":"2024-05-05T16:21:36.482550Z"},"trusted":true},"outputs":[],"source":["class Trainer:\n","  def __init__(self, config, model, optimizer, criterion, dataloader):\n","    self.config = config\n","    self.model = model\n","    self.optimizer = optimizer\n","    self.criterion = criterion\n","    self.dataloader = dataloader\n","    self.device = next(self.model.parameters()).device\n","\n","    # Initialize metric trackers for loss and accuracy\n","    self.losses = MetricTracker()\n","    self.accs = MetricTracker()\n","\n","    # Initialize evaluation instance for testing\n","    self.tester = Evaluation(self.config, self.model)\n","\n","  def train(self):\n","    # Iterate over epochs\n","    for epoch in range(self.config['num_epochs']):\n","      # Train for one epoch\n","      result = self._train_epoch(epoch)\n","      # Print epoch-level results\n","      print('Epoch: [{0}]\\t Avg Loss {loss:.4f}\\t Avg Accuracy {acc:.3f}'.format(epoch, loss=result['loss'], acc=result['acc']))\n","\n","      # Evaluate the model\n","      self.tester.eval()\n","      # Save the model if the current accuracy is the best so far\n","      if self.tester.best_acc == self.tester.accs.avg:\n","        print('Saving Model...')\n","        torch.save({\n","            'epoch': epoch,\n","            'model': self.model,\n","            'optimizer': self.optimizer\n","        }, 'best_model/model.pth.tar')\n","\n","  def _train_epoch(self, epoch_idx):\n","    # Set model to training mode\n","    self.model.train()\n","\n","    # Reset loss and accuracy trackers\n","    self.losses.reset()\n","    self.accs.reset()\n","\n","    # Iterate over batches of training data\n","    for batch_idx, (docs, labels, doc_lengths, sent_lengths) in enumerate(self.dataloader):\n","        batch_size = labels.size(0)\n","\n","        # Move data to device\n","        docs = docs.to(self.device)\n","        labels = labels.to(self.device)\n","        sent_lengths = sent_lengths.to(self.device)\n","        doc_lengths = doc_lengths.to(self.device)\n","\n","        # Zero the gradients\n","        self.optimizer.zero_grad()\n","\n","        # Forward pass through the model\n","        scores, word_att_weights, sentence_att_weights = self.model(docs, doc_lengths, sent_lengths)\n","\n","        # Calculate the loss\n","        loss = self.criterion(scores, labels)\n","        loss.backward()\n","\n","        # Clip gradients if specified\n","        if self.config['max_grad_norm'] is not None:\n","          torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config['max_grad_norm'])\n","\n","        # Update model parameters\n","        self.optimizer.step()\n","\n","        # Compute accuracy for the batch\n","        predictions = scores.max(dim=1)[1]\n","        correct_predictions = torch.eq(predictions, labels).sum().item()\n","        acc = correct_predictions\n","\n","        # Update loss and accuracy trackers\n","        self.losses.update(loss.item(), batch_size)\n","        self.accs.update(acc, batch_size)\n","\n","        # Print batch-level results\n","        print('Epoch: [{0}][{1}/{2}]\\t Loss {loss.val:.4f} ({loss.avg:.4f})\\t Accuracy {acc.val:.3f} ({acc.avg:.3f})'.format(epoch_idx, batch_idx, len(self.dataloader), loss=self.losses, acc=self.accs))\n","\n","    # Return epoch-level results\n","    log = {\n","        'loss': self.losses.avg,\n","        'acc': self.accs.avg\n","    }\n","    return log\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:36.500055Z","iopub.status.busy":"2024-05-05T16:21:36.499826Z","iopub.status.idle":"2024-05-05T16:21:36.514009Z","shell.execute_reply":"2024-05-05T16:21:36.513254Z","shell.execute_reply.started":"2024-05-05T16:21:36.500035Z"},"trusted":true},"outputs":[],"source":["def train(config, device):\n","  # Initialize training dataset and dataloader\n","  dataset = News20Dataset(config['vocab_path'], is_train=True)\n","  dataloader = MyDataLoader(dataset, batch_size=config['batch_size'])\n","\n","  # Initialize the model\n","  model = HierarchicalAttentionNetwork(\n","        num_classes=dataset.num_classes,\n","        vocab_size=dataset.vocab_size,\n","        embed_dim=config['embed_dim'],\n","        word_gru_hidden_dim=config['word_gru_hidden_dim'],\n","        sent_gru_hidden_dim=config['sent_gru_hidden_dim'],\n","        word_gru_num_layers=config['word_gru_num_layers'],\n","        sent_gru_num_layers=config['sent_gru_num_layers'],\n","        word_att_dim=config['word_att_dim'],\n","        sent_att_dim=config['sent_att_dim'],\n","        use_layer_norm=config['use_layer_norm'],\n","        dropout=config['dropout']\n","    ).to(device)\n","\n","  # Initialize optimizer\n","  optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, model.parameters()), lr=config['lr'])\n","\n","  # Initialize loss function\n","  criterion = nn.CrossEntropyLoss(reduction='sum').to(device)\n","\n","  # Initialize pretrained embeddings if specified\n","  if config['pretrain']:\n","    glove_pretrained = get_pretrained_weights(dataset.vocab, config['embed_dim'], device)\n","    model.sent_attention.word_attention.init_embeddings(glove_pretrained)\n","\n","  # Freeze embeddings if specified\n","  model.sent_attention.word_attention.freeze_embeddings(config['freeze'])\n","\n","  # Initialize trainer\n","  trainer = Trainer(config, model, optimizer, criterion, dataloader)\n","\n","  # Start training\n","  trainer.train()\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:36.515322Z","iopub.status.busy":"2024-05-05T16:21:36.515047Z","iopub.status.idle":"2024-05-05T16:21:36.531382Z","shell.execute_reply":"2024-05-05T16:21:36.530636Z","shell.execute_reply.started":"2024-05-05T16:21:36.515301Z"},"trusted":true},"outputs":[],"source":["import os\n","import torch\n","from tqdm import tqdm\n","from pylab import *\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","\n","import matplotlib\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:36.533099Z","iopub.status.busy":"2024-05-05T16:21:36.532575Z","iopub.status.idle":"2024-05-05T16:21:36.537682Z","shell.execute_reply":"2024-05-05T16:21:36.536853Z","shell.execute_reply.started":"2024-05-05T16:21:36.533076Z"},"trusted":true},"outputs":[],"source":["os.makedirs('best_model', exist_ok=True)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:36.538941Z","iopub.status.busy":"2024-05-05T16:21:36.538656Z","iopub.status.idle":"2024-05-05T16:21:36.548298Z","shell.execute_reply":"2024-05-05T16:21:36.547487Z","shell.execute_reply.started":"2024-05-05T16:21:36.538913Z"},"trusted":true},"outputs":[],"source":["def get_pretrained_weights(corpus_vocab, embed_dim, device):\n","  save_dir = os.path.join('glove_pretrained.pt')\n","  if os.path.exists(save_dir):\n","    return torch.load(save_dir, map_location=device)\n","\n","  corpus_set = set(corpus_vocab)\n","  pretrained_vocab = set()\n","  glove_pretrained = torch.zeros(len(corpus_vocab), embed_dim)\n","  with open(os.path.join('glove.6B.100d.txt'), 'rb') as f:\n","    for l in tqdm(f):\n","      line = l.decode().split()\n","      if line[0] in corpus_set:\n","        pretrained_vocab.add(line[0])\n","        glove_pretrained[corpus_vocab.index(line[0])] = torch.from_numpy(np.array(line[1:]).astype(float))\n","\n","    var = float(torch.var(glove_pretrained))\n","    for oov in corpus_set.difference(pretrained_vocab):\n","      glove_pretrained[corpus_vocab.index(oov)]  = torch.empty(100).float().uniform_(-var, var)\n","    print('weight size: ', glove_pretrained.size())\n","    torch.save(glove_pretrained, save_dir)\n","  return glove_pretrained"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:21:36.551317Z","iopub.status.busy":"2024-05-05T16:21:36.549375Z","iopub.status.idle":"2024-05-05T16:21:36.562052Z","shell.execute_reply":"2024-05-05T16:21:36.561243Z","shell.execute_reply.started":"2024-05-05T16:21:36.551285Z"},"trusted":true},"outputs":[],"source":["def map_sentence_to_color(words, scores, sent_score):\n","  sentencemap = matplotlib.cm.get_cmap('binary')\n","  wordmap = matplotlib.cm.get_cmap('OrRd')\n","  result = '<p><span style=\"margin:5px; padding:5px; background-color: {}\">'\\\n","    .format(matplotlib.colors.rgb2hex(sentencemap(sent_score)[:3]))\n","  template = '<span class=\"barcode\"; style=\"color: black; background-color: {}\">{}</span>'\n","  for word, score in zip(words, scores):\n","    color = matplotlib.colors.rgb2hex(wordmap(scores)[:3])\n","    result += template.format(color, '&nbsp' + word + '&nbsp')\n","  result += '</span><p>'\n","  return result"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T16:30:58.408749Z","iopub.status.busy":"2024-05-05T16:30:58.407983Z","iopub.status.idle":"2024-05-05T17:38:47.627217Z","shell.execute_reply":"2024-05-05T17:38:47.626181Z","shell.execute_reply.started":"2024-05-05T16:30:58.408718Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [0][0/38]\t Loss 1.3888 (1.3888)\t Accuracy 0.186 (0.186)\n","Epoch: [0][1/38]\t Loss 1.4145 (1.4021)\t Accuracy 0.270 (0.230)\n","Epoch: [0][2/38]\t Loss 1.3841 (1.3959)\t Accuracy 0.302 (0.254)\n","Epoch: [0][3/38]\t Loss 1.3328 (1.3803)\t Accuracy 0.377 (0.285)\n","Epoch: [0][4/38]\t Loss 1.4327 (1.3910)\t Accuracy 0.159 (0.259)\n","Epoch: [0][5/38]\t Loss 1.4163 (1.3952)\t Accuracy 0.246 (0.257)\n","Epoch: [0][6/38]\t Loss 1.3443 (1.3879)\t Accuracy 0.306 (0.264)\n","Epoch: [0][7/38]\t Loss 1.3703 (1.3857)\t Accuracy 0.177 (0.253)\n","Epoch: [0][8/38]\t Loss 1.3579 (1.3826)\t Accuracy 0.295 (0.258)\n","Epoch: [0][9/38]\t Loss 1.2962 (1.3739)\t Accuracy 0.516 (0.284)\n","Epoch: [0][10/38]\t Loss 1.3446 (1.3712)\t Accuracy 0.190 (0.275)\n","Epoch: [0][11/38]\t Loss 1.2011 (1.3570)\t Accuracy 0.403 (0.286)\n","Epoch: [0][12/38]\t Loss 1.2740 (1.3506)\t Accuracy 0.355 (0.291)\n","Epoch: [0][13/38]\t Loss 1.1137 (1.3334)\t Accuracy 0.619 (0.315)\n","Epoch: [0][14/38]\t Loss 1.0743 (1.3158)\t Accuracy 0.651 (0.338)\n","Epoch: [0][15/38]\t Loss 1.0156 (1.2968)\t Accuracy 0.651 (0.358)\n","Epoch: [0][16/38]\t Loss 0.9290 (1.2745)\t Accuracy 0.703 (0.378)\n","Epoch: [0][17/38]\t Loss 0.9569 (1.2569)\t Accuracy 0.629 (0.392)\n","Epoch: [0][18/38]\t Loss 0.8758 (1.2369)\t Accuracy 0.677 (0.407)\n","Epoch: [0][19/38]\t Loss 0.7554 (1.2125)\t Accuracy 0.651 (0.420)\n","Epoch: [0][20/38]\t Loss 0.7757 (1.1915)\t Accuracy 0.698 (0.433)\n","Epoch: [0][21/38]\t Loss 0.7989 (1.1737)\t Accuracy 0.694 (0.445)\n","Epoch: [0][22/38]\t Loss 0.7426 (1.1544)\t Accuracy 0.719 (0.457)\n","Epoch: [0][23/38]\t Loss 0.7679 (1.1382)\t Accuracy 0.667 (0.466)\n","Epoch: [0][24/38]\t Loss 0.6856 (1.1201)\t Accuracy 0.758 (0.478)\n","Epoch: [0][25/38]\t Loss 0.6006 (1.1000)\t Accuracy 0.730 (0.487)\n","Epoch: [0][26/38]\t Loss 0.6147 (1.0815)\t Accuracy 0.766 (0.498)\n","Epoch: [0][27/38]\t Loss 0.6247 (1.0651)\t Accuracy 0.810 (0.509)\n","Epoch: [0][28/38]\t Loss 0.5064 (1.0462)\t Accuracy 0.754 (0.517)\n","Epoch: [0][29/38]\t Loss 0.5414 (1.0292)\t Accuracy 0.778 (0.526)\n","Epoch: [0][30/38]\t Loss 0.7744 (1.0208)\t Accuracy 0.766 (0.534)\n","Epoch: [0][31/38]\t Loss 0.7681 (1.0128)\t Accuracy 0.714 (0.540)\n","Epoch: [0][32/38]\t Loss 0.6872 (1.0030)\t Accuracy 0.742 (0.546)\n","Epoch: [0][33/38]\t Loss 0.7779 (0.9966)\t Accuracy 0.721 (0.551)\n","Epoch: [0][34/38]\t Loss 0.3900 (0.9796)\t Accuracy 0.820 (0.558)\n","Epoch: [0][35/38]\t Loss 0.6948 (0.9718)\t Accuracy 0.790 (0.565)\n","Epoch: [0][36/38]\t Loss 0.8972 (0.9698)\t Accuracy 0.661 (0.567)\n","Epoch: [0][37/38]\t Loss 0.7120 (0.9692)\t Accuracy 0.800 (0.568)\n","Epoch: [0]\t Avg Loss 0.9692\t Avg Accuracy 0.568\n","Test Average Accuracy: 0.7511\n","Saving Model...\n","Epoch: [1][0/38]\t Loss 0.6214 (0.6214)\t Accuracy 0.774 (0.774)\n","Epoch: [1][1/38]\t Loss 0.6397 (0.6305)\t Accuracy 0.839 (0.806)\n","Epoch: [1][2/38]\t Loss 0.5962 (0.6192)\t Accuracy 0.787 (0.800)\n","Epoch: [1][3/38]\t Loss 0.3975 (0.5635)\t Accuracy 0.887 (0.822)\n","Epoch: [1][4/38]\t Loss 0.4698 (0.5443)\t Accuracy 0.844 (0.826)\n","Epoch: [1][5/38]\t Loss 0.5973 (0.5532)\t Accuracy 0.841 (0.829)\n","Epoch: [1][6/38]\t Loss 0.4692 (0.5416)\t Accuracy 0.783 (0.823)\n","Epoch: [1][7/38]\t Loss 0.3897 (0.5226)\t Accuracy 0.855 (0.827)\n","Epoch: [1][8/38]\t Loss 0.6049 (0.5319)\t Accuracy 0.746 (0.818)\n","Epoch: [1][9/38]\t Loss 0.4482 (0.5235)\t Accuracy 0.823 (0.818)\n","Epoch: [1][10/38]\t Loss 0.4424 (0.5162)\t Accuracy 0.823 (0.818)\n","Epoch: [1][11/38]\t Loss 0.4901 (0.5140)\t Accuracy 0.758 (0.813)\n","Epoch: [1][12/38]\t Loss 0.4634 (0.5101)\t Accuracy 0.823 (0.814)\n","Epoch: [1][13/38]\t Loss 0.5436 (0.5125)\t Accuracy 0.810 (0.814)\n","Epoch: [1][14/38]\t Loss 0.5830 (0.5172)\t Accuracy 0.742 (0.809)\n","Epoch: [1][15/38]\t Loss 0.4648 (0.5139)\t Accuracy 0.857 (0.812)\n","Epoch: [1][16/38]\t Loss 0.5390 (0.5154)\t Accuracy 0.770 (0.810)\n","Epoch: [1][17/38]\t Loss 0.4689 (0.5127)\t Accuracy 0.841 (0.811)\n","Epoch: [1][18/38]\t Loss 0.5552 (0.5150)\t Accuracy 0.812 (0.811)\n","Epoch: [1][19/38]\t Loss 0.5625 (0.5174)\t Accuracy 0.810 (0.811)\n","Epoch: [1][20/38]\t Loss 0.5216 (0.5176)\t Accuracy 0.812 (0.811)\n","Epoch: [1][21/38]\t Loss 0.5459 (0.5189)\t Accuracy 0.800 (0.811)\n","Epoch: [1][22/38]\t Loss 0.4651 (0.5165)\t Accuracy 0.873 (0.814)\n","Epoch: [1][23/38]\t Loss 0.6200 (0.5208)\t Accuracy 0.710 (0.809)\n","Epoch: [1][24/38]\t Loss 0.4284 (0.5171)\t Accuracy 0.823 (0.810)\n","Epoch: [1][25/38]\t Loss 0.4159 (0.5133)\t Accuracy 0.871 (0.812)\n","Epoch: [1][26/38]\t Loss 0.4352 (0.5103)\t Accuracy 0.841 (0.813)\n","Epoch: [1][27/38]\t Loss 0.5729 (0.5126)\t Accuracy 0.730 (0.810)\n","Epoch: [1][28/38]\t Loss 0.5605 (0.5142)\t Accuracy 0.836 (0.811)\n","Epoch: [1][29/38]\t Loss 0.4652 (0.5126)\t Accuracy 0.820 (0.811)\n","Epoch: [1][30/38]\t Loss 0.5037 (0.5123)\t Accuracy 0.797 (0.811)\n","Epoch: [1][31/38]\t Loss 0.3945 (0.5086)\t Accuracy 0.887 (0.813)\n","Epoch: [1][32/38]\t Loss 0.5231 (0.5091)\t Accuracy 0.820 (0.814)\n","Epoch: [1][33/38]\t Loss 0.6236 (0.5125)\t Accuracy 0.734 (0.811)\n","Epoch: [1][34/38]\t Loss 0.7801 (0.5204)\t Accuracy 0.688 (0.808)\n","Epoch: [1][35/38]\t Loss 0.6393 (0.5238)\t Accuracy 0.719 (0.805)\n","Epoch: [1][36/38]\t Loss 0.5187 (0.5236)\t Accuracy 0.803 (0.805)\n","Epoch: [1][37/38]\t Loss 0.3090 (0.5232)\t Accuracy 1.000 (0.805)\n","Epoch: [1]\t Avg Loss 0.5232\t Avg Accuracy 0.805\n","Test Average Accuracy: 0.7387\n","Epoch: [2][0/38]\t Loss 0.5360 (0.5360)\t Accuracy 0.758 (0.758)\n","Epoch: [2][1/38]\t Loss 0.4588 (0.4974)\t Accuracy 0.839 (0.798)\n","Epoch: [2][2/38]\t Loss 0.5550 (0.5164)\t Accuracy 0.738 (0.778)\n","Epoch: [2][3/38]\t Loss 0.4716 (0.5052)\t Accuracy 0.790 (0.781)\n","Epoch: [2][4/38]\t Loss 0.6558 (0.5362)\t Accuracy 0.734 (0.772)\n","Epoch: [2][5/38]\t Loss 0.3571 (0.5068)\t Accuracy 0.869 (0.788)\n","Epoch: [2][6/38]\t Loss 0.3198 (0.4794)\t Accuracy 0.875 (0.800)\n","Epoch: [2][7/38]\t Loss 0.4895 (0.4807)\t Accuracy 0.781 (0.798)\n","Epoch: [2][8/38]\t Loss 0.5957 (0.4933)\t Accuracy 0.726 (0.790)\n","Epoch: [2][9/38]\t Loss 0.6289 (0.5064)\t Accuracy 0.767 (0.788)\n","Epoch: [2][10/38]\t Loss 0.4508 (0.5014)\t Accuracy 0.839 (0.792)\n","Epoch: [2][11/38]\t Loss 0.5481 (0.5052)\t Accuracy 0.787 (0.792)\n","Epoch: [2][12/38]\t Loss 0.3991 (0.4968)\t Accuracy 0.844 (0.796)\n","Epoch: [2][13/38]\t Loss 0.3162 (0.4838)\t Accuracy 0.857 (0.800)\n","Epoch: [2][14/38]\t Loss 0.3341 (0.4735)\t Accuracy 0.891 (0.807)\n","Epoch: [2][15/38]\t Loss 0.4359 (0.4712)\t Accuracy 0.857 (0.810)\n","Epoch: [2][16/38]\t Loss 0.5213 (0.4741)\t Accuracy 0.762 (0.807)\n","Epoch: [2][17/38]\t Loss 0.5457 (0.4780)\t Accuracy 0.770 (0.805)\n","Epoch: [2][18/38]\t Loss 0.4581 (0.4770)\t Accuracy 0.787 (0.804)\n","Epoch: [2][19/38]\t Loss 0.5191 (0.4791)\t Accuracy 0.778 (0.803)\n","Epoch: [2][20/38]\t Loss 0.5006 (0.4801)\t Accuracy 0.803 (0.803)\n","Epoch: [2][21/38]\t Loss 0.3688 (0.4749)\t Accuracy 0.844 (0.805)\n","Epoch: [2][22/38]\t Loss 0.5644 (0.4789)\t Accuracy 0.810 (0.805)\n","Epoch: [2][23/38]\t Loss 0.5167 (0.4804)\t Accuracy 0.839 (0.806)\n","Epoch: [2][24/38]\t Loss 0.3386 (0.4750)\t Accuracy 0.864 (0.808)\n","Epoch: [2][25/38]\t Loss 0.4421 (0.4737)\t Accuracy 0.828 (0.809)\n","Epoch: [2][26/38]\t Loss 0.5446 (0.4764)\t Accuracy 0.823 (0.810)\n","Epoch: [2][27/38]\t Loss 0.4312 (0.4747)\t Accuracy 0.828 (0.810)\n","Epoch: [2][28/38]\t Loss 0.4247 (0.4730)\t Accuracy 0.855 (0.812)\n","Epoch: [2][29/38]\t Loss 0.4049 (0.4707)\t Accuracy 0.887 (0.814)\n","Epoch: [2][30/38]\t Loss 0.4789 (0.4710)\t Accuracy 0.825 (0.815)\n","Epoch: [2][31/38]\t Loss 0.3458 (0.4670)\t Accuracy 0.844 (0.816)\n","Epoch: [2][32/38]\t Loss 0.4953 (0.4679)\t Accuracy 0.810 (0.816)\n","Epoch: [2][33/38]\t Loss 0.4787 (0.4682)\t Accuracy 0.823 (0.816)\n","Epoch: [2][34/38]\t Loss 0.4803 (0.4685)\t Accuracy 0.806 (0.815)\n","Epoch: [2][35/38]\t Loss 0.3333 (0.4648)\t Accuracy 0.871 (0.817)\n","Epoch: [2][36/38]\t Loss 0.4686 (0.4649)\t Accuracy 0.820 (0.817)\n","Epoch: [2][37/38]\t Loss 0.0472 (0.4640)\t Accuracy 1.000 (0.817)\n","Epoch: [2]\t Avg Loss 0.4640\t Avg Accuracy 0.817\n","Test Average Accuracy: 0.7538\n","Saving Model...\n","Epoch: [3][0/38]\t Loss 0.4075 (0.4075)\t Accuracy 0.806 (0.806)\n","Epoch: [3][1/38]\t Loss 0.2983 (0.3529)\t Accuracy 0.855 (0.831)\n","Epoch: [3][2/38]\t Loss 0.5271 (0.4090)\t Accuracy 0.814 (0.825)\n","Epoch: [3][3/38]\t Loss 0.3468 (0.3933)\t Accuracy 0.887 (0.841)\n","Epoch: [3][4/38]\t Loss 0.5384 (0.4230)\t Accuracy 0.778 (0.828)\n","Epoch: [3][5/38]\t Loss 0.3899 (0.4174)\t Accuracy 0.823 (0.827)\n","Epoch: [3][6/38]\t Loss 0.5727 (0.4391)\t Accuracy 0.750 (0.816)\n","Epoch: [3][7/38]\t Loss 0.3241 (0.4244)\t Accuracy 0.921 (0.830)\n","Epoch: [3][8/38]\t Loss 0.5705 (0.4410)\t Accuracy 0.778 (0.824)\n","Epoch: [3][9/38]\t Loss 0.4565 (0.4425)\t Accuracy 0.869 (0.828)\n","Epoch: [3][10/38]\t Loss 0.4639 (0.4444)\t Accuracy 0.823 (0.828)\n","Epoch: [3][11/38]\t Loss 0.5170 (0.4507)\t Accuracy 0.766 (0.822)\n","Epoch: [3][12/38]\t Loss 0.3822 (0.4453)\t Accuracy 0.857 (0.825)\n","Epoch: [3][13/38]\t Loss 0.4686 (0.4470)\t Accuracy 0.825 (0.825)\n","Epoch: [3][14/38]\t Loss 0.4214 (0.4453)\t Accuracy 0.857 (0.827)\n","Epoch: [3][15/38]\t Loss 0.4450 (0.4453)\t Accuracy 0.839 (0.828)\n","Epoch: [3][16/38]\t Loss 0.5248 (0.4500)\t Accuracy 0.774 (0.825)\n","Epoch: [3][17/38]\t Loss 0.3544 (0.4446)\t Accuracy 0.873 (0.828)\n","Epoch: [3][18/38]\t Loss 0.4772 (0.4463)\t Accuracy 0.839 (0.828)\n","Epoch: [3][19/38]\t Loss 0.3122 (0.4396)\t Accuracy 0.919 (0.833)\n","Epoch: [3][20/38]\t Loss 0.5054 (0.4428)\t Accuracy 0.828 (0.832)\n","Epoch: [3][21/38]\t Loss 0.2954 (0.4362)\t Accuracy 0.852 (0.833)\n","Epoch: [3][22/38]\t Loss 0.3282 (0.4315)\t Accuracy 0.841 (0.834)\n","Epoch: [3][23/38]\t Loss 0.3726 (0.4290)\t Accuracy 0.841 (0.834)\n","Epoch: [3][24/38]\t Loss 0.4096 (0.4282)\t Accuracy 0.857 (0.835)\n","Epoch: [3][25/38]\t Loss 0.3526 (0.4253)\t Accuracy 0.855 (0.836)\n","Epoch: [3][26/38]\t Loss 0.5413 (0.4295)\t Accuracy 0.783 (0.834)\n","Epoch: [3][27/38]\t Loss 0.4611 (0.4306)\t Accuracy 0.885 (0.836)\n","Epoch: [3][28/38]\t Loss 0.5470 (0.4347)\t Accuracy 0.797 (0.834)\n","Epoch: [3][29/38]\t Loss 0.4629 (0.4357)\t Accuracy 0.859 (0.835)\n","Epoch: [3][30/38]\t Loss 0.3721 (0.4336)\t Accuracy 0.857 (0.836)\n","Epoch: [3][31/38]\t Loss 0.3572 (0.4313)\t Accuracy 0.867 (0.837)\n","Epoch: [3][32/38]\t Loss 0.3826 (0.4298)\t Accuracy 0.825 (0.836)\n","Epoch: [3][33/38]\t Loss 0.5112 (0.4322)\t Accuracy 0.825 (0.836)\n","Epoch: [3][34/38]\t Loss 0.3218 (0.4290)\t Accuracy 0.857 (0.837)\n","Epoch: [3][35/38]\t Loss 0.4689 (0.4301)\t Accuracy 0.841 (0.837)\n","Epoch: [3][36/38]\t Loss 0.6755 (0.4370)\t Accuracy 0.719 (0.834)\n","Epoch: [3][37/38]\t Loss 0.6439 (0.4374)\t Accuracy 0.800 (0.833)\n","Epoch: [3]\t Avg Loss 0.4374\t Avg Accuracy 0.833\n","Test Average Accuracy: 0.7426\n","Epoch: [4][0/38]\t Loss 0.4222 (0.4222)\t Accuracy 0.855 (0.855)\n","Epoch: [4][1/38]\t Loss 0.4619 (0.4424)\t Accuracy 0.812 (0.833)\n","Epoch: [4][2/38]\t Loss 0.3697 (0.4187)\t Accuracy 0.885 (0.850)\n","Epoch: [4][3/38]\t Loss 0.3253 (0.3948)\t Accuracy 0.875 (0.857)\n","Epoch: [4][4/38]\t Loss 0.3965 (0.3952)\t Accuracy 0.857 (0.857)\n","Epoch: [4][5/38]\t Loss 0.3279 (0.3842)\t Accuracy 0.869 (0.859)\n","Epoch: [4][6/38]\t Loss 0.5520 (0.4077)\t Accuracy 0.705 (0.837)\n","Epoch: [4][7/38]\t Loss 0.3941 (0.4060)\t Accuracy 0.855 (0.839)\n","Epoch: [4][8/38]\t Loss 0.5063 (0.4173)\t Accuracy 0.778 (0.832)\n","Epoch: [4][9/38]\t Loss 0.3379 (0.4094)\t Accuracy 0.919 (0.841)\n","Epoch: [4][10/38]\t Loss 0.2789 (0.3976)\t Accuracy 0.855 (0.842)\n","Epoch: [4][11/38]\t Loss 0.3953 (0.3974)\t Accuracy 0.859 (0.844)\n","Epoch: [4][12/38]\t Loss 0.2158 (0.3837)\t Accuracy 0.918 (0.849)\n","Epoch: [4][13/38]\t Loss 0.2629 (0.3750)\t Accuracy 0.905 (0.853)\n","Epoch: [4][14/38]\t Loss 0.2622 (0.3673)\t Accuracy 0.906 (0.857)\n","Epoch: [4][15/38]\t Loss 0.3828 (0.3683)\t Accuracy 0.844 (0.856)\n","Epoch: [4][16/38]\t Loss 0.5064 (0.3765)\t Accuracy 0.778 (0.852)\n","Epoch: [4][17/38]\t Loss 0.4414 (0.3800)\t Accuracy 0.823 (0.850)\n","Epoch: [4][18/38]\t Loss 0.2381 (0.3727)\t Accuracy 0.934 (0.854)\n","Epoch: [4][19/38]\t Loss 0.6688 (0.3874)\t Accuracy 0.726 (0.848)\n","Epoch: [4][20/38]\t Loss 0.4904 (0.3924)\t Accuracy 0.825 (0.847)\n","Epoch: [4][21/38]\t Loss 0.2370 (0.3855)\t Accuracy 0.934 (0.851)\n","Epoch: [4][22/38]\t Loss 0.4556 (0.3884)\t Accuracy 0.833 (0.850)\n","Epoch: [4][23/38]\t Loss 0.3853 (0.3883)\t Accuracy 0.794 (0.848)\n","Epoch: [4][24/38]\t Loss 0.2684 (0.3835)\t Accuracy 0.871 (0.849)\n","Epoch: [4][25/38]\t Loss 0.5373 (0.3896)\t Accuracy 0.781 (0.846)\n","Epoch: [4][26/38]\t Loss 0.2171 (0.3832)\t Accuracy 0.935 (0.849)\n","Epoch: [4][27/38]\t Loss 0.3670 (0.3826)\t Accuracy 0.906 (0.851)\n","Epoch: [4][28/38]\t Loss 0.2718 (0.3787)\t Accuracy 0.891 (0.853)\n","Epoch: [4][29/38]\t Loss 0.4750 (0.3819)\t Accuracy 0.823 (0.852)\n","Epoch: [4][30/38]\t Loss 0.2537 (0.3778)\t Accuracy 0.903 (0.853)\n","Epoch: [4][31/38]\t Loss 0.4020 (0.3785)\t Accuracy 0.845 (0.853)\n","Epoch: [4][32/38]\t Loss 0.4305 (0.3800)\t Accuracy 0.852 (0.853)\n","Epoch: [4][33/38]\t Loss 0.4649 (0.3825)\t Accuracy 0.823 (0.852)\n","Epoch: [4][34/38]\t Loss 0.2906 (0.3798)\t Accuracy 0.906 (0.854)\n","Epoch: [4][35/38]\t Loss 0.3679 (0.3795)\t Accuracy 0.825 (0.853)\n","Epoch: [4][36/38]\t Loss 0.4220 (0.3807)\t Accuracy 0.825 (0.852)\n","Epoch: [4][37/38]\t Loss 0.0308 (0.3799)\t Accuracy 1.000 (0.853)\n","Epoch: [4]\t Avg Loss 0.3799\t Avg Accuracy 0.853\n","Test Average Accuracy: 0.7505\n","Epoch: [5][0/38]\t Loss 0.4086 (0.4086)\t Accuracy 0.836 (0.836)\n","Epoch: [5][1/38]\t Loss 0.2578 (0.3320)\t Accuracy 0.889 (0.863)\n","Epoch: [5][2/38]\t Loss 0.3195 (0.3277)\t Accuracy 0.891 (0.872)\n","Epoch: [5][3/38]\t Loss 0.6488 (0.4083)\t Accuracy 0.698 (0.829)\n","Epoch: [5][4/38]\t Loss 0.3955 (0.4058)\t Accuracy 0.823 (0.827)\n","Epoch: [5][5/38]\t Loss 0.2902 (0.3864)\t Accuracy 0.873 (0.835)\n","Epoch: [5][6/38]\t Loss 0.3673 (0.3838)\t Accuracy 0.867 (0.839)\n","Epoch: [5][7/38]\t Loss 0.1169 (0.3496)\t Accuracy 0.984 (0.858)\n","Epoch: [5][8/38]\t Loss 0.3078 (0.3451)\t Accuracy 0.885 (0.861)\n","Epoch: [5][9/38]\t Loss 0.3722 (0.3477)\t Accuracy 0.852 (0.860)\n","Epoch: [5][10/38]\t Loss 0.3091 (0.3441)\t Accuracy 0.844 (0.859)\n","Epoch: [5][11/38]\t Loss 0.4204 (0.3504)\t Accuracy 0.869 (0.859)\n","Epoch: [5][12/38]\t Loss 0.4479 (0.3581)\t Accuracy 0.875 (0.861)\n","Epoch: [5][13/38]\t Loss 0.2306 (0.3490)\t Accuracy 0.935 (0.866)\n","Epoch: [5][14/38]\t Loss 0.3626 (0.3499)\t Accuracy 0.871 (0.866)\n","Epoch: [5][15/38]\t Loss 0.2904 (0.3462)\t Accuracy 0.857 (0.866)\n","Epoch: [5][16/38]\t Loss 0.3757 (0.3479)\t Accuracy 0.903 (0.868)\n","Epoch: [5][17/38]\t Loss 0.3289 (0.3468)\t Accuracy 0.887 (0.869)\n","Epoch: [5][18/38]\t Loss 0.3697 (0.3480)\t Accuracy 0.836 (0.867)\n","Epoch: [5][19/38]\t Loss 0.5993 (0.3605)\t Accuracy 0.790 (0.863)\n","Epoch: [5][20/38]\t Loss 0.2897 (0.3571)\t Accuracy 0.889 (0.865)\n","Epoch: [5][21/38]\t Loss 0.2595 (0.3526)\t Accuracy 0.938 (0.868)\n","Epoch: [5][22/38]\t Loss 0.2777 (0.3493)\t Accuracy 0.887 (0.869)\n","Epoch: [5][23/38]\t Loss 0.3292 (0.3485)\t Accuracy 0.852 (0.868)\n","Epoch: [5][24/38]\t Loss 0.3015 (0.3466)\t Accuracy 0.873 (0.868)\n","Epoch: [5][25/38]\t Loss 0.2400 (0.3425)\t Accuracy 0.903 (0.870)\n","Epoch: [5][26/38]\t Loss 0.2417 (0.3388)\t Accuracy 0.952 (0.873)\n","Epoch: [5][27/38]\t Loss 0.3563 (0.3394)\t Accuracy 0.889 (0.873)\n","Epoch: [5][28/38]\t Loss 0.2702 (0.3370)\t Accuracy 0.885 (0.874)\n","Epoch: [5][29/38]\t Loss 0.4891 (0.3423)\t Accuracy 0.781 (0.871)\n","Epoch: [5][30/38]\t Loss 0.3651 (0.3430)\t Accuracy 0.852 (0.870)\n","Epoch: [5][31/38]\t Loss 0.2660 (0.3406)\t Accuracy 0.919 (0.872)\n","Epoch: [5][32/38]\t Loss 0.3695 (0.3415)\t Accuracy 0.823 (0.870)\n","Epoch: [5][33/38]\t Loss 0.3190 (0.3408)\t Accuracy 0.921 (0.872)\n","Epoch: [5][34/38]\t Loss 0.2791 (0.3390)\t Accuracy 0.922 (0.873)\n","Epoch: [5][35/38]\t Loss 0.3315 (0.3388)\t Accuracy 0.902 (0.874)\n","Epoch: [5][36/38]\t Loss 0.2931 (0.3375)\t Accuracy 0.889 (0.874)\n","Epoch: [5][37/38]\t Loss 0.1084 (0.3370)\t Accuracy 1.000 (0.875)\n","Epoch: [5]\t Avg Loss 0.3370\t Avg Accuracy 0.875\n","Test Average Accuracy: 0.7754\n","Saving Model...\n","Epoch: [6][0/38]\t Loss 0.2189 (0.2189)\t Accuracy 0.934 (0.934)\n","Epoch: [6][1/38]\t Loss 0.3360 (0.2788)\t Accuracy 0.859 (0.896)\n","Epoch: [6][2/38]\t Loss 0.2465 (0.2686)\t Accuracy 0.914 (0.902)\n","Epoch: [6][3/38]\t Loss 0.2755 (0.2704)\t Accuracy 0.889 (0.898)\n","Epoch: [6][4/38]\t Loss 0.2274 (0.2617)\t Accuracy 0.903 (0.899)\n","Epoch: [6][5/38]\t Loss 0.2647 (0.2622)\t Accuracy 0.887 (0.897)\n","Epoch: [6][6/38]\t Loss 0.2015 (0.2536)\t Accuracy 0.918 (0.900)\n","Epoch: [6][7/38]\t Loss 0.1789 (0.2441)\t Accuracy 0.952 (0.907)\n","Epoch: [6][8/38]\t Loss 0.3128 (0.2519)\t Accuracy 0.873 (0.903)\n","Epoch: [6][9/38]\t Loss 0.3594 (0.2628)\t Accuracy 0.921 (0.905)\n","Test Average Accuracy: 0.7702\n","Epoch: [7][0/38]\t Loss 0.2362 (0.2362)\t Accuracy 0.937 (0.937)\n","Epoch: [7][1/38]\t Loss 0.3480 (0.2912)\t Accuracy 0.803 (0.871)\n","Epoch: [7][2/38]\t Loss 0.2232 (0.2683)\t Accuracy 0.905 (0.882)\n","Epoch: [7][3/38]\t Loss 0.1138 (0.2294)\t Accuracy 0.984 (0.908)\n","Epoch: [7][4/38]\t Loss 0.3818 (0.2593)\t Accuracy 0.869 (0.900)\n","Epoch: [7][5/38]\t Loss 0.2527 (0.2581)\t Accuracy 0.937 (0.906)\n","Epoch: [7][6/38]\t Loss 0.2912 (0.2629)\t Accuracy 0.873 (0.902)\n","Epoch: [7][7/38]\t Loss 0.2601 (0.2626)\t Accuracy 0.922 (0.904)\n","Epoch: [7][8/38]\t Loss 0.2171 (0.2576)\t Accuracy 0.934 (0.907)\n","Epoch: [7][9/38]\t Loss 0.2363 (0.2555)\t Accuracy 0.905 (0.907)\n","Epoch: [7][10/38]\t Loss 0.1849 (0.2490)\t Accuracy 0.937 (0.910)\n","Epoch: [7][11/38]\t Loss 0.1126 (0.2374)\t Accuracy 0.969 (0.915)\n","Epoch: [7][12/38]\t Loss 0.1805 (0.2329)\t Accuracy 0.938 (0.917)\n","Epoch: [7][13/38]\t Loss 0.1326 (0.2257)\t Accuracy 0.968 (0.920)\n","Epoch: [7][14/38]\t Loss 0.2826 (0.2294)\t Accuracy 0.852 (0.916)\n","Epoch: [7][15/38]\t Loss 0.1813 (0.2264)\t Accuracy 0.968 (0.919)\n","Epoch: [7][16/38]\t Loss 0.1639 (0.2228)\t Accuracy 0.934 (0.920)\n","Epoch: [7][17/38]\t Loss 0.2438 (0.2240)\t Accuracy 0.903 (0.919)\n","Epoch: [7][18/38]\t Loss 0.2198 (0.2238)\t Accuracy 0.885 (0.917)\n","Epoch: [7][19/38]\t Loss 0.1836 (0.2218)\t Accuracy 0.919 (0.918)\n","Epoch: [7][20/38]\t Loss 0.1649 (0.2191)\t Accuracy 0.952 (0.919)\n","Epoch: [7][21/38]\t Loss 0.1335 (0.2152)\t Accuracy 0.952 (0.921)\n","Epoch: [7][22/38]\t Loss 0.2964 (0.2186)\t Accuracy 0.902 (0.920)\n","Epoch: [7][23/38]\t Loss 0.2179 (0.2186)\t Accuracy 0.919 (0.920)\n","Epoch: [7][24/38]\t Loss 0.1942 (0.2176)\t Accuracy 0.933 (0.920)\n","Epoch: [7][25/38]\t Loss 0.3602 (0.2232)\t Accuracy 0.857 (0.918)\n","Epoch: [7][26/38]\t Loss 0.2190 (0.2230)\t Accuracy 0.938 (0.919)\n","Epoch: [7][27/38]\t Loss 0.2132 (0.2227)\t Accuracy 0.921 (0.919)\n","Epoch: [7][28/38]\t Loss 0.2312 (0.2229)\t Accuracy 0.897 (0.918)\n","Epoch: [7][29/38]\t Loss 0.4231 (0.2296)\t Accuracy 0.839 (0.915)\n","Epoch: [7][30/38]\t Loss 0.2805 (0.2312)\t Accuracy 0.900 (0.915)\n","Epoch: [7][31/38]\t Loss 0.4090 (0.2369)\t Accuracy 0.891 (0.914)\n","Epoch: [7][32/38]\t Loss 0.3204 (0.2394)\t Accuracy 0.855 (0.912)\n","Epoch: [7][33/38]\t Loss 0.2731 (0.2404)\t Accuracy 0.873 (0.911)\n","Epoch: [7][34/38]\t Loss 0.2797 (0.2416)\t Accuracy 0.905 (0.911)\n","Epoch: [7][35/38]\t Loss 0.1711 (0.2395)\t Accuracy 0.969 (0.913)\n","Epoch: [7][36/38]\t Loss 0.4685 (0.2459)\t Accuracy 0.844 (0.911)\n","Epoch: [7][37/38]\t Loss 0.6197 (0.2467)\t Accuracy 0.800 (0.910)\n","Epoch: [7]\t Avg Loss 0.2467\t Avg Accuracy 0.910\n","Test Average Accuracy: 0.7787\n","Saving Model...\n","Epoch: [8][0/38]\t Loss 0.2288 (0.2288)\t Accuracy 0.887 (0.887)\n","Epoch: [8][1/38]\t Loss 0.2821 (0.2557)\t Accuracy 0.937 (0.912)\n","Epoch: [8][2/38]\t Loss 0.2038 (0.2386)\t Accuracy 0.934 (0.919)\n","Epoch: [8][3/38]\t Loss 0.2676 (0.2460)\t Accuracy 0.921 (0.920)\n","Epoch: [8][4/38]\t Loss 0.1820 (0.2331)\t Accuracy 0.968 (0.929)\n","Epoch: [8][5/38]\t Loss 0.1071 (0.2119)\t Accuracy 0.968 (0.936)\n","Epoch: [8][6/38]\t Loss 0.2105 (0.2117)\t Accuracy 0.885 (0.929)\n","Epoch: [8][7/38]\t Loss 0.1793 (0.2077)\t Accuracy 0.919 (0.928)\n","Epoch: [8][8/38]\t Loss 0.2768 (0.2154)\t Accuracy 0.889 (0.923)\n","Epoch: [8][9/38]\t Loss 0.1659 (0.2104)\t Accuracy 0.952 (0.926)\n","Epoch: [8][10/38]\t Loss 0.1826 (0.2079)\t Accuracy 0.921 (0.926)\n","Epoch: [8][11/38]\t Loss 0.1788 (0.2055)\t Accuracy 0.935 (0.927)\n","Epoch: [8][12/38]\t Loss 0.1183 (0.1989)\t Accuracy 0.967 (0.930)\n","Epoch: [8][13/38]\t Loss 0.1860 (0.1980)\t Accuracy 0.932 (0.930)\n","Epoch: [8][14/38]\t Loss 0.1137 (0.1924)\t Accuracy 0.952 (0.931)\n","Epoch: [8][15/38]\t Loss 0.2060 (0.1933)\t Accuracy 0.938 (0.932)\n","Epoch: [8][16/38]\t Loss 0.1773 (0.1923)\t Accuracy 0.937 (0.932)\n","Epoch: [8][17/38]\t Loss 0.2046 (0.1930)\t Accuracy 0.889 (0.930)\n","Epoch: [8][18/38]\t Loss 0.1752 (0.1921)\t Accuracy 0.919 (0.929)\n","Epoch: [8][19/38]\t Loss 0.3885 (0.2019)\t Accuracy 0.855 (0.925)\n","Epoch: [8][20/38]\t Loss 0.1326 (0.1986)\t Accuracy 0.952 (0.927)\n","Epoch: [8][21/38]\t Loss 0.2411 (0.2005)\t Accuracy 0.935 (0.927)\n","Epoch: [8][22/38]\t Loss 0.3800 (0.2082)\t Accuracy 0.918 (0.927)\n","Epoch: [8][23/38]\t Loss 0.2347 (0.2093)\t Accuracy 0.937 (0.927)\n","Epoch: [8][24/38]\t Loss 0.2439 (0.2107)\t Accuracy 0.887 (0.925)\n","Epoch: [8][25/38]\t Loss 0.2660 (0.2128)\t Accuracy 0.889 (0.924)\n","Epoch: [8][26/38]\t Loss 0.1097 (0.2089)\t Accuracy 0.984 (0.926)\n","Epoch: [8][27/38]\t Loss 0.1699 (0.2075)\t Accuracy 0.918 (0.926)\n","Epoch: [8][28/38]\t Loss 0.1155 (0.2044)\t Accuracy 0.952 (0.927)\n","Epoch: [8][29/38]\t Loss 0.2076 (0.2045)\t Accuracy 0.905 (0.926)\n","Epoch: [8][30/38]\t Loss 0.1204 (0.2017)\t Accuracy 0.969 (0.928)\n","Epoch: [8][31/38]\t Loss 0.1264 (0.1993)\t Accuracy 0.984 (0.929)\n","Epoch: [8][32/38]\t Loss 0.2011 (0.1994)\t Accuracy 0.935 (0.929)\n","Epoch: [8][33/38]\t Loss 0.2468 (0.2008)\t Accuracy 0.875 (0.928)\n","Epoch: [8][34/38]\t Loss 0.1755 (0.2001)\t Accuracy 0.935 (0.928)\n","Epoch: [8][35/38]\t Loss 0.1528 (0.1988)\t Accuracy 0.937 (0.928)\n","Epoch: [8][36/38]\t Loss 0.3110 (0.2018)\t Accuracy 0.871 (0.927)\n","Epoch: [8][37/38]\t Loss 1.1426 (0.2038)\t Accuracy 0.600 (0.926)\n","Epoch: [8]\t Avg Loss 0.2038\t Avg Accuracy 0.926\n","Test Average Accuracy: 0.7689\n","Epoch: [9][0/38]\t Loss 0.3405 (0.3405)\t Accuracy 0.873 (0.873)\n","Epoch: [9][1/38]\t Loss 0.1813 (0.2622)\t Accuracy 0.934 (0.903)\n","Epoch: [9][2/38]\t Loss 0.1824 (0.2353)\t Accuracy 0.937 (0.914)\n","Epoch: [9][3/38]\t Loss 0.1317 (0.2092)\t Accuracy 0.937 (0.920)\n","Epoch: [9][4/38]\t Loss 0.1608 (0.1996)\t Accuracy 0.952 (0.926)\n","Epoch: [9][5/38]\t Loss 0.1200 (0.1868)\t Accuracy 0.950 (0.930)\n","Epoch: [9][6/38]\t Loss 0.2618 (0.1976)\t Accuracy 0.937 (0.931)\n","Epoch: [9][7/38]\t Loss 0.1412 (0.1905)\t Accuracy 0.937 (0.932)\n","Epoch: [9][8/38]\t Loss 0.1595 (0.1870)\t Accuracy 0.935 (0.932)\n","Epoch: [9][9/38]\t Loss 0.3569 (0.2040)\t Accuracy 0.855 (0.924)\n","Epoch: [9][10/38]\t Loss 0.1264 (0.1970)\t Accuracy 0.951 (0.927)\n","Epoch: [9][11/38]\t Loss 0.1168 (0.1903)\t Accuracy 0.968 (0.930)\n","Epoch: [9][12/38]\t Loss 0.1722 (0.1889)\t Accuracy 0.951 (0.932)\n","Epoch: [9][13/38]\t Loss 0.1783 (0.1882)\t Accuracy 0.935 (0.932)\n","Epoch: [9][14/38]\t Loss 0.1448 (0.1853)\t Accuracy 0.918 (0.931)\n","Epoch: [9][15/38]\t Loss 0.1417 (0.1826)\t Accuracy 0.952 (0.932)\n","Epoch: [9][16/38]\t Loss 0.1443 (0.1803)\t Accuracy 0.969 (0.935)\n","Epoch: [9][17/38]\t Loss 0.3255 (0.1886)\t Accuracy 0.891 (0.932)\n","Epoch: [9][18/38]\t Loss 0.1691 (0.1875)\t Accuracy 0.935 (0.932)\n","Epoch: [9][19/38]\t Loss 0.3239 (0.1943)\t Accuracy 0.919 (0.932)\n","Epoch: [9][20/38]\t Loss 0.3378 (0.2010)\t Accuracy 0.869 (0.929)\n","Epoch: [9][21/38]\t Loss 0.4384 (0.2121)\t Accuracy 0.844 (0.925)\n","Epoch: [9][22/38]\t Loss 0.1442 (0.2092)\t Accuracy 0.952 (0.926)\n","Epoch: [9][23/38]\t Loss 0.1399 (0.2062)\t Accuracy 0.937 (0.926)\n","Epoch: [9][24/38]\t Loss 0.2495 (0.2080)\t Accuracy 0.905 (0.926)\n","Epoch: [9][25/38]\t Loss 0.3003 (0.2115)\t Accuracy 0.871 (0.923)\n","Epoch: [9][26/38]\t Loss 0.2812 (0.2142)\t Accuracy 0.844 (0.920)\n","Epoch: [9][27/38]\t Loss 0.1805 (0.2130)\t Accuracy 0.952 (0.922)\n","Epoch: [9][28/38]\t Loss 0.1189 (0.2097)\t Accuracy 0.952 (0.923)\n","Epoch: [9][29/38]\t Loss 0.0946 (0.2060)\t Accuracy 0.967 (0.924)\n","Epoch: [9][30/38]\t Loss 0.2726 (0.2081)\t Accuracy 0.903 (0.923)\n","Epoch: [9][31/38]\t Loss 0.1594 (0.2066)\t Accuracy 0.937 (0.924)\n","Epoch: [9][32/38]\t Loss 0.3158 (0.2098)\t Accuracy 0.902 (0.923)\n","Epoch: [9][33/38]\t Loss 0.3439 (0.2139)\t Accuracy 0.891 (0.922)\n","Epoch: [9][34/38]\t Loss 0.2247 (0.2142)\t Accuracy 0.935 (0.923)\n","Epoch: [9][35/38]\t Loss 0.2754 (0.2159)\t Accuracy 0.921 (0.922)\n","Epoch: [9][36/38]\t Loss 0.1604 (0.2144)\t Accuracy 0.935 (0.923)\n","Epoch: [9][37/38]\t Loss 0.3004 (0.2146)\t Accuracy 0.800 (0.923)\n","Epoch: [9]\t Avg Loss 0.2146\t Avg Accuracy 0.923\n","Test Average Accuracy: 0.7735\n","Epoch: [10][0/38]\t Loss 0.2572 (0.2572)\t Accuracy 0.917 (0.917)\n","Epoch: [10][1/38]\t Loss 0.1075 (0.1812)\t Accuracy 0.968 (0.943)\n","Epoch: [10][2/38]\t Loss 0.2249 (0.1962)\t Accuracy 0.906 (0.930)\n","Epoch: [10][3/38]\t Loss 0.1621 (0.1876)\t Accuracy 0.952 (0.936)\n","Epoch: [10][4/38]\t Loss 0.1158 (0.1729)\t Accuracy 0.969 (0.942)\n","Epoch: [10][5/38]\t Loss 0.1899 (0.1757)\t Accuracy 0.935 (0.941)\n","Epoch: [10][6/38]\t Loss 0.1891 (0.1776)\t Accuracy 0.934 (0.940)\n","Epoch: [10][7/38]\t Loss 0.2394 (0.1854)\t Accuracy 0.952 (0.942)\n","Epoch: [10][8/38]\t Loss 0.1838 (0.1852)\t Accuracy 0.922 (0.940)\n","Epoch: [10][9/38]\t Loss 0.2480 (0.1915)\t Accuracy 0.889 (0.935)\n","Epoch: [10][10/38]\t Loss 0.1776 (0.1902)\t Accuracy 0.953 (0.936)\n","Epoch: [10][11/38]\t Loss 0.2117 (0.1919)\t Accuracy 0.932 (0.936)\n","Epoch: [10][12/38]\t Loss 0.1371 (0.1877)\t Accuracy 0.952 (0.937)\n","Epoch: [10][13/38]\t Loss 0.0697 (0.1794)\t Accuracy 0.984 (0.940)\n","Epoch: [10][14/38]\t Loss 0.1888 (0.1801)\t Accuracy 0.919 (0.939)\n","Epoch: [10][15/38]\t Loss 0.3383 (0.1900)\t Accuracy 0.905 (0.937)\n","Epoch: [10][16/38]\t Loss 0.0888 (0.1842)\t Accuracy 0.984 (0.940)\n","Epoch: [10][17/38]\t Loss 0.1333 (0.1814)\t Accuracy 0.937 (0.939)\n","Epoch: [10][18/38]\t Loss 0.2159 (0.1832)\t Accuracy 0.968 (0.941)\n","Epoch: [10][19/38]\t Loss 0.3367 (0.1908)\t Accuracy 0.871 (0.937)\n","Epoch: [10][20/38]\t Loss 0.1695 (0.1898)\t Accuracy 0.921 (0.937)\n","Epoch: [10][21/38]\t Loss 0.1857 (0.1896)\t Accuracy 0.905 (0.935)\n","Epoch: [10][22/38]\t Loss 0.1822 (0.1893)\t Accuracy 0.952 (0.936)\n","Epoch: [10][23/38]\t Loss 0.1300 (0.1869)\t Accuracy 0.951 (0.936)\n","Epoch: [10][24/38]\t Loss 0.1213 (0.1842)\t Accuracy 0.969 (0.938)\n","Epoch: [10][25/38]\t Loss 0.1502 (0.1828)\t Accuracy 0.953 (0.938)\n","Epoch: [10][26/38]\t Loss 0.1101 (0.1802)\t Accuracy 0.967 (0.939)\n","Epoch: [10][27/38]\t Loss 0.1542 (0.1793)\t Accuracy 0.951 (0.940)\n","Epoch: [10][28/38]\t Loss 0.1252 (0.1774)\t Accuracy 0.968 (0.941)\n","Epoch: [10][29/38]\t Loss 0.0943 (0.1747)\t Accuracy 0.984 (0.942)\n","Epoch: [10][30/38]\t Loss 0.2784 (0.1782)\t Accuracy 0.906 (0.941)\n","Epoch: [10][31/38]\t Loss 0.1215 (0.1764)\t Accuracy 0.952 (0.941)\n","Epoch: [10][32/38]\t Loss 0.0635 (0.1730)\t Accuracy 0.984 (0.943)\n","Epoch: [10][33/38]\t Loss 0.1740 (0.1730)\t Accuracy 0.951 (0.943)\n","Epoch: [10][34/38]\t Loss 0.0533 (0.1696)\t Accuracy 0.984 (0.944)\n","Epoch: [10][35/38]\t Loss 0.1752 (0.1698)\t Accuracy 0.937 (0.944)\n","Epoch: [10][36/38]\t Loss 0.1581 (0.1695)\t Accuracy 0.953 (0.944)\n","Epoch: [10][37/38]\t Loss 0.3571 (0.1699)\t Accuracy 0.800 (0.944)\n","Epoch: [10]\t Avg Loss 0.1699\t Avg Accuracy 0.944\n","Test Average Accuracy: 0.7794\n","Saving Model...\n","Epoch: [11][0/38]\t Loss 0.0712 (0.0712)\t Accuracy 0.968 (0.968)\n","Epoch: [11][1/38]\t Loss 0.0904 (0.0807)\t Accuracy 0.952 (0.960)\n","Epoch: [11][2/38]\t Loss 0.2817 (0.1480)\t Accuracy 0.921 (0.947)\n","Epoch: [11][3/38]\t Loss 0.0893 (0.1337)\t Accuracy 0.951 (0.948)\n","Epoch: [11][4/38]\t Loss 0.0691 (0.1206)\t Accuracy 0.952 (0.949)\n","Epoch: [11][5/38]\t Loss 0.1261 (0.1215)\t Accuracy 0.935 (0.947)\n","Epoch: [11][6/38]\t Loss 0.0780 (0.1153)\t Accuracy 0.984 (0.952)\n","Epoch: [11][7/38]\t Loss 0.1219 (0.1162)\t Accuracy 0.968 (0.954)\n","Epoch: [11][8/38]\t Loss 0.0856 (0.1128)\t Accuracy 0.968 (0.955)\n","Epoch: [11][9/38]\t Loss 0.1143 (0.1129)\t Accuracy 0.984 (0.958)\n","Epoch: [11][10/38]\t Loss 0.1578 (0.1170)\t Accuracy 0.935 (0.956)\n","Epoch: [11][11/38]\t Loss 0.2536 (0.1283)\t Accuracy 0.919 (0.953)\n","Epoch: [11][12/38]\t Loss 0.0902 (0.1254)\t Accuracy 0.984 (0.956)\n","Epoch: [11][13/38]\t Loss 0.0773 (0.1220)\t Accuracy 0.984 (0.957)\n","Epoch: [11][14/38]\t Loss 0.1138 (0.1215)\t Accuracy 0.952 (0.957)\n","Epoch: [11][15/38]\t Loss 0.0763 (0.1187)\t Accuracy 0.968 (0.958)\n","Epoch: [11][16/38]\t Loss 0.1801 (0.1223)\t Accuracy 0.935 (0.956)\n","Epoch: [11][17/38]\t Loss 0.1151 (0.1219)\t Accuracy 0.968 (0.957)\n","Epoch: [11][18/38]\t Loss 0.1397 (0.1228)\t Accuracy 0.934 (0.956)\n","Epoch: [11][19/38]\t Loss 0.1028 (0.1218)\t Accuracy 0.968 (0.956)\n","Epoch: [11][20/38]\t Loss 0.2567 (0.1282)\t Accuracy 0.887 (0.953)\n","Epoch: [11][21/38]\t Loss 0.2093 (0.1319)\t Accuracy 0.952 (0.953)\n","Epoch: [11][22/38]\t Loss 0.0789 (0.1295)\t Accuracy 0.984 (0.955)\n","Epoch: [11][23/38]\t Loss 0.1011 (0.1283)\t Accuracy 0.984 (0.956)\n","Epoch: [11][24/38]\t Loss 0.1314 (0.1285)\t Accuracy 0.953 (0.956)\n","Epoch: [11][25/38]\t Loss 0.1655 (0.1299)\t Accuracy 0.921 (0.954)\n","Epoch: [11][26/38]\t Loss 0.1773 (0.1316)\t Accuracy 0.951 (0.954)\n","Epoch: [11][27/38]\t Loss 0.1006 (0.1305)\t Accuracy 0.967 (0.955)\n","Epoch: [11][28/38]\t Loss 0.0926 (0.1292)\t Accuracy 0.968 (0.955)\n","Epoch: [11][29/38]\t Loss 0.0598 (0.1269)\t Accuracy 0.984 (0.956)\n","Epoch: [11][30/38]\t Loss 0.2233 (0.1301)\t Accuracy 0.906 (0.954)\n","Epoch: [11][31/38]\t Loss 0.1173 (0.1297)\t Accuracy 0.953 (0.954)\n","Epoch: [11][32/38]\t Loss 0.2341 (0.1328)\t Accuracy 0.903 (0.953)\n","Epoch: [11][33/38]\t Loss 0.2179 (0.1353)\t Accuracy 0.968 (0.953)\n","Epoch: [11][34/38]\t Loss 0.2176 (0.1377)\t Accuracy 0.905 (0.952)\n","Epoch: [11][35/38]\t Loss 0.1373 (0.1377)\t Accuracy 0.952 (0.952)\n","Epoch: [11][36/38]\t Loss 0.1420 (0.1378)\t Accuracy 0.921 (0.951)\n","Epoch: [11][37/38]\t Loss 0.4052 (0.1384)\t Accuracy 0.800 (0.951)\n","Epoch: [11]\t Avg Loss 0.1384\t Avg Accuracy 0.951\n","Test Average Accuracy: 0.7768\n","Epoch: [12][0/38]\t Loss 0.0419 (0.0419)\t Accuracy 0.984 (0.984)\n","Epoch: [12][1/38]\t Loss 0.1834 (0.1121)\t Accuracy 0.934 (0.959)\n","Epoch: [12][2/38]\t Loss 0.0685 (0.0975)\t Accuracy 0.984 (0.968)\n","Epoch: [12][3/38]\t Loss 0.1516 (0.1107)\t Accuracy 0.950 (0.963)\n","Epoch: [12][4/38]\t Loss 0.1539 (0.1194)\t Accuracy 0.952 (0.961)\n","Epoch: [12][5/38]\t Loss 0.1877 (0.1309)\t Accuracy 0.919 (0.954)\n","Epoch: [12][6/38]\t Loss 0.1003 (0.1266)\t Accuracy 0.967 (0.956)\n","Epoch: [12][7/38]\t Loss 0.1836 (0.1340)\t Accuracy 0.922 (0.951)\n","Epoch: [12][8/38]\t Loss 0.1843 (0.1395)\t Accuracy 0.967 (0.953)\n","Epoch: [12][9/38]\t Loss 0.0694 (0.1324)\t Accuracy 0.984 (0.956)\n","Epoch: [12][10/38]\t Loss 0.0879 (0.1284)\t Accuracy 0.968 (0.957)\n","Epoch: [12][11/38]\t Loss 0.0836 (0.1246)\t Accuracy 0.968 (0.958)\n","Epoch: [12][12/38]\t Loss 0.1509 (0.1267)\t Accuracy 0.935 (0.956)\n","Epoch: [12][13/38]\t Loss 0.1969 (0.1318)\t Accuracy 0.921 (0.954)\n","Epoch: [12][14/38]\t Loss 0.1898 (0.1356)\t Accuracy 0.952 (0.954)\n","Epoch: [12][15/38]\t Loss 0.1294 (0.1353)\t Accuracy 0.951 (0.953)\n","Epoch: [12][16/38]\t Loss 0.1572 (0.1366)\t Accuracy 0.952 (0.953)\n","Epoch: [12][17/38]\t Loss 0.0555 (0.1320)\t Accuracy 0.968 (0.954)\n","Epoch: [12][18/38]\t Loss 0.0547 (0.1278)\t Accuracy 1.000 (0.957)\n","Epoch: [12][19/38]\t Loss 0.1350 (0.1282)\t Accuracy 0.937 (0.956)\n","Epoch: [12][20/38]\t Loss 0.0576 (0.1247)\t Accuracy 0.984 (0.957)\n","Epoch: [12][21/38]\t Loss 0.1450 (0.1257)\t Accuracy 0.952 (0.957)\n","Epoch: [12][22/38]\t Loss 0.0471 (0.1223)\t Accuracy 0.984 (0.958)\n","Epoch: [12][23/38]\t Loss 0.0597 (0.1197)\t Accuracy 1.000 (0.960)\n","Epoch: [12][24/38]\t Loss 0.0421 (0.1166)\t Accuracy 0.984 (0.961)\n","Epoch: [12][25/38]\t Loss 0.0980 (0.1158)\t Accuracy 0.968 (0.961)\n","Epoch: [12][26/38]\t Loss 0.1837 (0.1184)\t Accuracy 0.922 (0.960)\n","Epoch: [12][27/38]\t Loss 0.0922 (0.1175)\t Accuracy 0.984 (0.960)\n","Epoch: [12][28/38]\t Loss 0.1589 (0.1189)\t Accuracy 0.935 (0.960)\n","Epoch: [12][29/38]\t Loss 0.5748 (0.1343)\t Accuracy 0.873 (0.957)\n","Epoch: [12][30/38]\t Loss 0.1996 (0.1364)\t Accuracy 0.859 (0.953)\n","Epoch: [12][31/38]\t Loss 0.1038 (0.1354)\t Accuracy 0.969 (0.954)\n","Epoch: [12][32/38]\t Loss 0.0892 (0.1340)\t Accuracy 0.967 (0.954)\n","Epoch: [12][33/38]\t Loss 0.1512 (0.1345)\t Accuracy 0.938 (0.954)\n","Epoch: [12][34/38]\t Loss 0.2384 (0.1375)\t Accuracy 0.919 (0.953)\n","Epoch: [12][35/38]\t Loss 0.1716 (0.1384)\t Accuracy 0.952 (0.953)\n","Epoch: [12][36/38]\t Loss 0.1066 (0.1376)\t Accuracy 0.952 (0.953)\n","Epoch: [12][37/38]\t Loss 0.2706 (0.1379)\t Accuracy 0.800 (0.952)\n","Epoch: [12]\t Avg Loss 0.1379\t Avg Accuracy 0.952\n","Test Average Accuracy: 0.7787\n","Epoch: [13][0/38]\t Loss 0.1998 (0.1998)\t Accuracy 0.937 (0.937)\n","Epoch: [13][1/38]\t Loss 0.0334 (0.1166)\t Accuracy 1.000 (0.968)\n","Epoch: [13][2/38]\t Loss 0.2209 (0.1513)\t Accuracy 0.937 (0.958)\n","Epoch: [13][3/38]\t Loss 0.0722 (0.1323)\t Accuracy 0.983 (0.964)\n","Epoch: [13][4/38]\t Loss 0.0877 (0.1234)\t Accuracy 0.968 (0.965)\n","Epoch: [13][5/38]\t Loss 0.0832 (0.1167)\t Accuracy 0.984 (0.968)\n","Epoch: [13][6/38]\t Loss 0.1330 (0.1190)\t Accuracy 0.952 (0.966)\n","Epoch: [13][7/38]\t Loss 0.0545 (0.1112)\t Accuracy 0.983 (0.968)\n","Epoch: [13][8/38]\t Loss 0.1015 (0.1101)\t Accuracy 0.968 (0.968)\n","Epoch: [13][9/38]\t Loss 0.1270 (0.1118)\t Accuracy 0.918 (0.963)\n","Epoch: [13][10/38]\t Loss 0.1115 (0.1118)\t Accuracy 0.968 (0.963)\n","Epoch: [13][11/38]\t Loss 0.0873 (0.1097)\t Accuracy 0.968 (0.964)\n","Epoch: [13][12/38]\t Loss 0.0418 (0.1044)\t Accuracy 0.984 (0.965)\n","Epoch: [13][13/38]\t Loss 0.0423 (0.0999)\t Accuracy 1.000 (0.968)\n","Epoch: [13][14/38]\t Loss 0.0670 (0.0977)\t Accuracy 0.968 (0.968)\n","Epoch: [13][15/38]\t Loss 0.0579 (0.0951)\t Accuracy 0.984 (0.969)\n","Epoch: [13][16/38]\t Loss 0.1090 (0.0959)\t Accuracy 0.968 (0.969)\n","Epoch: [13][17/38]\t Loss 0.0305 (0.0923)\t Accuracy 1.000 (0.971)\n","Epoch: [13][18/38]\t Loss 0.1111 (0.0933)\t Accuracy 0.938 (0.969)\n","Epoch: [13][19/38]\t Loss 0.0907 (0.0931)\t Accuracy 0.952 (0.968)\n","Epoch: [13][20/38]\t Loss 0.1275 (0.0948)\t Accuracy 0.935 (0.966)\n","Epoch: [13][21/38]\t Loss 0.1051 (0.0952)\t Accuracy 0.967 (0.967)\n","Epoch: [13][22/38]\t Loss 0.1578 (0.0979)\t Accuracy 0.934 (0.965)\n","Epoch: [13][23/38]\t Loss 0.0215 (0.0947)\t Accuracy 1.000 (0.967)\n","Epoch: [13][24/38]\t Loss 0.0760 (0.0939)\t Accuracy 0.968 (0.967)\n","Epoch: [13][25/38]\t Loss 0.1952 (0.0979)\t Accuracy 0.937 (0.965)\n","Epoch: [13][26/38]\t Loss 0.0663 (0.0967)\t Accuracy 0.968 (0.966)\n","Epoch: [13][27/38]\t Loss 0.1205 (0.0975)\t Accuracy 0.951 (0.965)\n","Epoch: [13][28/38]\t Loss 0.0590 (0.0962)\t Accuracy 0.968 (0.965)\n","Epoch: [13][29/38]\t Loss 0.0271 (0.0938)\t Accuracy 0.984 (0.966)\n","Epoch: [13][30/38]\t Loss 0.0569 (0.0926)\t Accuracy 0.984 (0.966)\n","Epoch: [13][31/38]\t Loss 0.2360 (0.0972)\t Accuracy 0.937 (0.965)\n","Epoch: [13][32/38]\t Loss 0.0489 (0.0958)\t Accuracy 0.983 (0.966)\n","Epoch: [13][33/38]\t Loss 0.0268 (0.0938)\t Accuracy 0.984 (0.966)\n","Epoch: [13][34/38]\t Loss 0.0751 (0.0933)\t Accuracy 1.000 (0.967)\n","Epoch: [13][35/38]\t Loss 0.0260 (0.0914)\t Accuracy 0.984 (0.968)\n","Epoch: [13][36/38]\t Loss 0.0766 (0.0910)\t Accuracy 0.968 (0.968)\n","Epoch: [13][37/38]\t Loss 0.0004 (0.0908)\t Accuracy 1.000 (0.968)\n","Epoch: [13]\t Avg Loss 0.0908\t Avg Accuracy 0.968\n","Test Average Accuracy: 0.7669\n","Epoch: [14][0/38]\t Loss 0.0499 (0.0499)\t Accuracy 0.984 (0.984)\n","Epoch: [14][1/38]\t Loss 0.0642 (0.0570)\t Accuracy 0.968 (0.976)\n","Epoch: [14][2/38]\t Loss 0.2530 (0.1231)\t Accuracy 0.921 (0.957)\n","Epoch: [14][3/38]\t Loss 0.1258 (0.1238)\t Accuracy 0.969 (0.960)\n","Epoch: [14][4/38]\t Loss 0.1000 (0.1190)\t Accuracy 0.953 (0.959)\n","Epoch: [14][5/38]\t Loss 0.0638 (0.1101)\t Accuracy 0.983 (0.963)\n","Epoch: [14][6/38]\t Loss 0.0842 (0.1065)\t Accuracy 0.984 (0.966)\n","Epoch: [14][7/38]\t Loss 0.0388 (0.0983)\t Accuracy 1.000 (0.970)\n","Epoch: [14][8/38]\t Loss 0.0965 (0.0981)\t Accuracy 0.984 (0.971)\n","Epoch: [14][9/38]\t Loss 0.0846 (0.0967)\t Accuracy 0.968 (0.971)\n","Epoch: [14][10/38]\t Loss 0.0870 (0.0959)\t Accuracy 0.967 (0.971)\n","Epoch: [14][11/38]\t Loss 0.0614 (0.0930)\t Accuracy 0.968 (0.970)\n","Epoch: [14][12/38]\t Loss 0.0402 (0.0890)\t Accuracy 0.984 (0.971)\n","Epoch: [14][13/38]\t Loss 0.0711 (0.0877)\t Accuracy 0.968 (0.971)\n","Epoch: [14][14/38]\t Loss 0.1957 (0.0951)\t Accuracy 0.922 (0.968)\n","Epoch: [14][15/38]\t Loss 0.1352 (0.0976)\t Accuracy 0.937 (0.966)\n","Epoch: [14][16/38]\t Loss 0.2453 (0.1064)\t Accuracy 0.952 (0.965)\n","Epoch: [14][17/38]\t Loss 0.0889 (0.1054)\t Accuracy 0.952 (0.964)\n","Epoch: [14][18/38]\t Loss 0.1573 (0.1082)\t Accuracy 0.969 (0.965)\n","Epoch: [14][19/38]\t Loss 0.1602 (0.1108)\t Accuracy 0.918 (0.962)\n","Epoch: [14][20/38]\t Loss 0.2838 (0.1192)\t Accuracy 0.891 (0.959)\n","Epoch: [14][21/38]\t Loss 0.1870 (0.1223)\t Accuracy 0.903 (0.956)\n","Epoch: [14][22/38]\t Loss 0.0231 (0.1180)\t Accuracy 1.000 (0.958)\n","Epoch: [14][23/38]\t Loss 0.2271 (0.1226)\t Accuracy 0.952 (0.958)\n","Epoch: [14][24/38]\t Loss 0.1594 (0.1240)\t Accuracy 0.934 (0.957)\n","Epoch: [14][25/38]\t Loss 0.0360 (0.1205)\t Accuracy 0.969 (0.957)\n","Epoch: [14][26/38]\t Loss 0.1584 (0.1220)\t Accuracy 0.922 (0.956)\n","Epoch: [14][27/38]\t Loss 0.1673 (0.1236)\t Accuracy 0.935 (0.955)\n","Epoch: [14][28/38]\t Loss 0.1250 (0.1236)\t Accuracy 0.951 (0.955)\n","Epoch: [14][29/38]\t Loss 0.0733 (0.1220)\t Accuracy 0.949 (0.955)\n","Epoch: [14][30/38]\t Loss 0.0720 (0.1205)\t Accuracy 0.951 (0.955)\n","Epoch: [14][31/38]\t Loss 0.0979 (0.1197)\t Accuracy 0.935 (0.954)\n","Epoch: [14][32/38]\t Loss 0.1329 (0.1202)\t Accuracy 0.953 (0.954)\n","Epoch: [14][33/38]\t Loss 0.1159 (0.1200)\t Accuracy 0.937 (0.954)\n","Epoch: [14][34/38]\t Loss 0.0564 (0.1182)\t Accuracy 0.968 (0.954)\n","Epoch: [14][35/38]\t Loss 0.0375 (0.1159)\t Accuracy 1.000 (0.955)\n","Epoch: [14][36/38]\t Loss 0.0818 (0.1150)\t Accuracy 0.969 (0.956)\n","Epoch: [14][37/38]\t Loss 0.3548 (0.1155)\t Accuracy 0.800 (0.955)\n","Epoch: [14]\t Avg Loss 0.1155\t Avg Accuracy 0.955\n","Test Average Accuracy: 0.7827\n","Saving Model...\n","Epoch: [15][0/38]\t Loss 0.0315 (0.0315)\t Accuracy 1.000 (1.000)\n","Epoch: [15][1/38]\t Loss 0.0844 (0.0579)\t Accuracy 0.984 (0.992)\n","Epoch: [15][2/38]\t Loss 0.1131 (0.0759)\t Accuracy 0.952 (0.979)\n","Epoch: [15][3/38]\t Loss 0.1433 (0.0925)\t Accuracy 0.935 (0.968)\n","Epoch: [15][4/38]\t Loss 0.0369 (0.0814)\t Accuracy 1.000 (0.975)\n","Epoch: [15][5/38]\t Loss 0.0329 (0.0733)\t Accuracy 0.984 (0.976)\n","Epoch: [15][6/38]\t Loss 0.0802 (0.0743)\t Accuracy 0.984 (0.977)\n","Epoch: [15][7/38]\t Loss 0.0032 (0.0655)\t Accuracy 1.000 (0.980)\n","Epoch: [15][8/38]\t Loss 0.0842 (0.0675)\t Accuracy 0.984 (0.980)\n","Epoch: [15][9/38]\t Loss 0.0827 (0.0691)\t Accuracy 0.938 (0.976)\n","Epoch: [15][10/38]\t Loss 0.1595 (0.0771)\t Accuracy 0.967 (0.975)\n","Epoch: [15][11/38]\t Loss 0.0910 (0.0782)\t Accuracy 0.949 (0.973)\n","Epoch: [15][12/38]\t Loss 0.0270 (0.0742)\t Accuracy 0.984 (0.974)\n","Epoch: [15][13/38]\t Loss 0.0806 (0.0747)\t Accuracy 0.984 (0.975)\n","Epoch: [15][14/38]\t Loss 0.1444 (0.0794)\t Accuracy 0.968 (0.974)\n","Epoch: [15][15/38]\t Loss 0.0690 (0.0788)\t Accuracy 0.966 (0.974)\n","Epoch: [15][16/38]\t Loss 0.2276 (0.0878)\t Accuracy 0.922 (0.971)\n","Epoch: [15][17/38]\t Loss 0.0615 (0.0863)\t Accuracy 0.984 (0.971)\n","Epoch: [15][18/38]\t Loss 0.0371 (0.0837)\t Accuracy 0.984 (0.972)\n","Epoch: [15][19/38]\t Loss 0.0787 (0.0835)\t Accuracy 0.967 (0.972)\n","Epoch: [15][20/38]\t Loss 0.0369 (0.0813)\t Accuracy 1.000 (0.973)\n","Epoch: [15][21/38]\t Loss 0.0312 (0.0789)\t Accuracy 1.000 (0.974)\n","Epoch: [15][22/38]\t Loss 0.1246 (0.0810)\t Accuracy 0.938 (0.973)\n","Epoch: [15][23/38]\t Loss 0.0610 (0.0801)\t Accuracy 0.969 (0.973)\n","Epoch: [15][24/38]\t Loss 0.0444 (0.0787)\t Accuracy 0.984 (0.973)\n","Epoch: [15][25/38]\t Loss 0.0902 (0.0791)\t Accuracy 0.968 (0.973)\n","Epoch: [15][26/38]\t Loss 0.1166 (0.0805)\t Accuracy 0.935 (0.971)\n","Epoch: [15][27/38]\t Loss 0.0201 (0.0784)\t Accuracy 1.000 (0.972)\n","Epoch: [15][28/38]\t Loss 0.1179 (0.0798)\t Accuracy 0.935 (0.971)\n","Epoch: [15][29/38]\t Loss 0.1414 (0.0818)\t Accuracy 0.952 (0.971)\n","Epoch: [15][30/38]\t Loss 0.1128 (0.0828)\t Accuracy 0.933 (0.969)\n","Epoch: [15][31/38]\t Loss 0.2170 (0.0871)\t Accuracy 0.921 (0.968)\n","Epoch: [15][32/38]\t Loss 0.0193 (0.0849)\t Accuracy 1.000 (0.969)\n","Epoch: [15][33/38]\t Loss 0.0208 (0.0831)\t Accuracy 1.000 (0.970)\n","Epoch: [15][34/38]\t Loss 0.0794 (0.0830)\t Accuracy 0.968 (0.970)\n","Epoch: [15][35/38]\t Loss 0.0511 (0.0821)\t Accuracy 0.984 (0.970)\n","Epoch: [15][36/38]\t Loss 0.0251 (0.0805)\t Accuracy 1.000 (0.971)\n","Epoch: [15][37/38]\t Loss 0.0091 (0.0804)\t Accuracy 1.000 (0.971)\n","Epoch: [15]\t Avg Loss 0.0804\t Avg Accuracy 0.971\n","Test Average Accuracy: 0.7636\n","Epoch: [16][0/38]\t Loss 0.0228 (0.0228)\t Accuracy 1.000 (1.000)\n","Epoch: [16][1/38]\t Loss 0.0519 (0.0376)\t Accuracy 0.984 (0.992)\n","Epoch: [16][2/38]\t Loss 0.0962 (0.0573)\t Accuracy 0.969 (0.984)\n","Epoch: [16][3/38]\t Loss 0.0843 (0.0641)\t Accuracy 0.984 (0.984)\n","Epoch: [16][4/38]\t Loss 0.0588 (0.0630)\t Accuracy 1.000 (0.987)\n","Epoch: [16][5/38]\t Loss 0.0447 (0.0600)\t Accuracy 0.984 (0.987)\n","Epoch: [16][6/38]\t Loss 0.0670 (0.0610)\t Accuracy 0.968 (0.984)\n","Epoch: [16][7/38]\t Loss 0.0626 (0.0612)\t Accuracy 0.984 (0.984)\n","Epoch: [16][8/38]\t Loss 0.1353 (0.0692)\t Accuracy 0.934 (0.979)\n","Epoch: [16][9/38]\t Loss 0.0194 (0.0642)\t Accuracy 1.000 (0.981)\n","Epoch: [16][10/38]\t Loss 0.1106 (0.0684)\t Accuracy 0.968 (0.980)\n","Epoch: [16][11/38]\t Loss 0.0648 (0.0681)\t Accuracy 0.968 (0.979)\n","Epoch: [16][12/38]\t Loss 0.0352 (0.0656)\t Accuracy 0.984 (0.979)\n","Epoch: [16][13/38]\t Loss 0.0233 (0.0628)\t Accuracy 1.000 (0.981)\n","Epoch: [16][14/38]\t Loss 0.0726 (0.0635)\t Accuracy 0.969 (0.980)\n","Epoch: [16][15/38]\t Loss 0.2350 (0.0739)\t Accuracy 0.918 (0.976)\n","Epoch: [16][16/38]\t Loss 0.0348 (0.0717)\t Accuracy 0.984 (0.976)\n","Epoch: [16][17/38]\t Loss 0.0865 (0.0725)\t Accuracy 0.984 (0.977)\n","Epoch: [16][18/38]\t Loss 0.0921 (0.0735)\t Accuracy 0.969 (0.976)\n","Epoch: [16][19/38]\t Loss 0.1451 (0.0770)\t Accuracy 0.950 (0.975)\n","Epoch: [16][20/38]\t Loss 0.0414 (0.0752)\t Accuracy 0.984 (0.976)\n","Epoch: [16][21/38]\t Loss 0.1884 (0.0804)\t Accuracy 0.935 (0.974)\n","Epoch: [16][22/38]\t Loss 0.0553 (0.0793)\t Accuracy 0.983 (0.974)\n","Epoch: [16][23/38]\t Loss 0.0696 (0.0789)\t Accuracy 0.969 (0.974)\n","Epoch: [16][24/38]\t Loss 0.1024 (0.0798)\t Accuracy 0.953 (0.973)\n","Epoch: [16][25/38]\t Loss 0.0223 (0.0776)\t Accuracy 1.000 (0.974)\n","Epoch: [16][26/38]\t Loss 0.0825 (0.0778)\t Accuracy 0.967 (0.974)\n","Epoch: [16][27/38]\t Loss 0.0539 (0.0770)\t Accuracy 0.984 (0.974)\n","Epoch: [16][28/38]\t Loss 0.1818 (0.0806)\t Accuracy 0.968 (0.974)\n","Epoch: [16][29/38]\t Loss 0.0519 (0.0797)\t Accuracy 0.984 (0.974)\n","Epoch: [16][30/38]\t Loss 0.1208 (0.0810)\t Accuracy 0.952 (0.974)\n","Epoch: [16][31/38]\t Loss 0.0286 (0.0794)\t Accuracy 0.984 (0.974)\n","Epoch: [16][32/38]\t Loss 0.1029 (0.0801)\t Accuracy 0.968 (0.974)\n","Epoch: [16][33/38]\t Loss 0.0393 (0.0789)\t Accuracy 1.000 (0.975)\n","Epoch: [16][34/38]\t Loss 0.0938 (0.0794)\t Accuracy 0.938 (0.973)\n","Epoch: [16][35/38]\t Loss 0.0386 (0.0782)\t Accuracy 0.984 (0.974)\n","Epoch: [16][36/38]\t Loss 0.1136 (0.0792)\t Accuracy 0.968 (0.974)\n","Epoch: [16][37/38]\t Loss 0.2192 (0.0795)\t Accuracy 0.800 (0.973)\n","Epoch: [16]\t Avg Loss 0.0795\t Avg Accuracy 0.973\n","Test Average Accuracy: 0.7728\n","Epoch: [17][0/38]\t Loss 0.0578 (0.0578)\t Accuracy 0.968 (0.968)\n","Epoch: [17][1/38]\t Loss 0.0574 (0.0576)\t Accuracy 0.969 (0.968)\n","Epoch: [17][2/38]\t Loss 0.0251 (0.0472)\t Accuracy 1.000 (0.978)\n","Epoch: [17][3/38]\t Loss 0.0629 (0.0513)\t Accuracy 0.969 (0.976)\n","Epoch: [17][4/38]\t Loss 0.0417 (0.0494)\t Accuracy 0.984 (0.977)\n","Epoch: [17][5/38]\t Loss 0.0583 (0.0509)\t Accuracy 0.984 (0.979)\n","Epoch: [17][6/38]\t Loss 0.0165 (0.0461)\t Accuracy 1.000 (0.982)\n","Epoch: [17][7/38]\t Loss 0.1176 (0.0550)\t Accuracy 0.984 (0.982)\n","Epoch: [17][8/38]\t Loss 0.0599 (0.0555)\t Accuracy 0.968 (0.980)\n","Epoch: [17][9/38]\t Loss 0.0548 (0.0555)\t Accuracy 0.984 (0.981)\n","Epoch: [17][10/38]\t Loss 0.0793 (0.0576)\t Accuracy 0.968 (0.980)\n","Epoch: [17][11/38]\t Loss 0.0899 (0.0603)\t Accuracy 0.968 (0.979)\n","Epoch: [17][12/38]\t Loss 0.1457 (0.0669)\t Accuracy 0.937 (0.975)\n","Epoch: [17][13/38]\t Loss 0.0270 (0.0641)\t Accuracy 0.984 (0.976)\n","Epoch: [17][14/38]\t Loss 0.0066 (0.0604)\t Accuracy 1.000 (0.978)\n","Epoch: [17][15/38]\t Loss 0.0244 (0.0582)\t Accuracy 1.000 (0.979)\n","Epoch: [17][16/38]\t Loss 0.0312 (0.0566)\t Accuracy 0.984 (0.979)\n","Epoch: [17][17/38]\t Loss 0.0559 (0.0565)\t Accuracy 0.984 (0.980)\n","Epoch: [17][18/38]\t Loss 0.0317 (0.0552)\t Accuracy 0.984 (0.980)\n","Epoch: [17][19/38]\t Loss 0.0193 (0.0534)\t Accuracy 1.000 (0.981)\n","Epoch: [17][20/38]\t Loss 0.0090 (0.0513)\t Accuracy 1.000 (0.982)\n","Epoch: [17][21/38]\t Loss 0.0211 (0.0500)\t Accuracy 0.984 (0.982)\n","Epoch: [17][22/38]\t Loss 0.1697 (0.0551)\t Accuracy 0.934 (0.980)\n","Epoch: [17][23/38]\t Loss 0.2149 (0.0617)\t Accuracy 0.903 (0.977)\n","Epoch: [17][24/38]\t Loss 0.1284 (0.0644)\t Accuracy 0.968 (0.976)\n","Epoch: [17][25/38]\t Loss 0.1581 (0.0680)\t Accuracy 0.952 (0.975)\n","Epoch: [17][26/38]\t Loss 0.1667 (0.0716)\t Accuracy 0.952 (0.974)\n","Epoch: [17][27/38]\t Loss 0.0050 (0.0693)\t Accuracy 1.000 (0.975)\n","Epoch: [17][28/38]\t Loss 0.1167 (0.0710)\t Accuracy 0.968 (0.975)\n","Epoch: [17][29/38]\t Loss 0.0761 (0.0711)\t Accuracy 0.969 (0.975)\n","Epoch: [17][30/38]\t Loss 0.1247 (0.0728)\t Accuracy 0.951 (0.974)\n","Epoch: [17][31/38]\t Loss 0.0659 (0.0726)\t Accuracy 0.984 (0.974)\n","Epoch: [17][32/38]\t Loss 0.0664 (0.0724)\t Accuracy 0.968 (0.974)\n","Epoch: [17][33/38]\t Loss 0.0407 (0.0715)\t Accuracy 0.984 (0.975)\n","Epoch: [17][34/38]\t Loss 0.0163 (0.0700)\t Accuracy 1.000 (0.975)\n","Epoch: [17][35/38]\t Loss 0.0734 (0.0701)\t Accuracy 0.984 (0.976)\n","Epoch: [17][36/38]\t Loss 0.1267 (0.0716)\t Accuracy 0.937 (0.974)\n","Epoch: [17][37/38]\t Loss 0.0000 (0.0715)\t Accuracy 1.000 (0.974)\n","Epoch: [17]\t Avg Loss 0.0715\t Avg Accuracy 0.974\n","Test Average Accuracy: 0.7932\n","Saving Model...\n","Epoch: [18][0/38]\t Loss 0.0696 (0.0696)\t Accuracy 0.967 (0.967)\n","Epoch: [18][1/38]\t Loss 0.0963 (0.0831)\t Accuracy 0.984 (0.975)\n","Epoch: [18][2/38]\t Loss 0.0250 (0.0635)\t Accuracy 1.000 (0.984)\n","Epoch: [18][3/38]\t Loss 0.0373 (0.0569)\t Accuracy 0.984 (0.984)\n","Epoch: [18][4/38]\t Loss 0.0058 (0.0468)\t Accuracy 1.000 (0.987)\n","Epoch: [18][5/38]\t Loss 0.0162 (0.0416)\t Accuracy 1.000 (0.989)\n","Epoch: [18][6/38]\t Loss 0.0180 (0.0381)\t Accuracy 1.000 (0.991)\n","Epoch: [18][7/38]\t Loss 0.0871 (0.0444)\t Accuracy 0.968 (0.988)\n","Epoch: [18][8/38]\t Loss 0.0496 (0.0449)\t Accuracy 0.968 (0.986)\n","Epoch: [18][9/38]\t Loss 0.0213 (0.0426)\t Accuracy 1.000 (0.987)\n","Epoch: [18][10/38]\t Loss 0.1042 (0.0483)\t Accuracy 0.952 (0.984)\n","Epoch: [18][11/38]\t Loss 0.0359 (0.0472)\t Accuracy 0.984 (0.984)\n","Epoch: [18][12/38]\t Loss 0.1322 (0.0539)\t Accuracy 0.937 (0.980)\n","Epoch: [18][13/38]\t Loss 0.0594 (0.0543)\t Accuracy 0.984 (0.980)\n","Epoch: [18][14/38]\t Loss 0.0961 (0.0571)\t Accuracy 0.984 (0.981)\n","Epoch: [18][15/38]\t Loss 0.0197 (0.0547)\t Accuracy 1.000 (0.982)\n","Epoch: [18][16/38]\t Loss 0.0574 (0.0549)\t Accuracy 0.984 (0.982)\n","Epoch: [18][17/38]\t Loss 0.0568 (0.0550)\t Accuracy 0.968 (0.981)\n","Epoch: [18][18/38]\t Loss 0.0176 (0.0530)\t Accuracy 1.000 (0.982)\n","Epoch: [18][19/38]\t Loss 0.0769 (0.0542)\t Accuracy 0.983 (0.982)\n","Epoch: [18][20/38]\t Loss 0.0339 (0.0532)\t Accuracy 0.984 (0.982)\n","Epoch: [18][21/38]\t Loss 0.0065 (0.0510)\t Accuracy 1.000 (0.983)\n","Epoch: [18][22/38]\t Loss 0.0260 (0.0499)\t Accuracy 0.984 (0.983)\n","Epoch: [18][23/38]\t Loss 0.0269 (0.0490)\t Accuracy 1.000 (0.984)\n","Epoch: [18][24/38]\t Loss 0.0018 (0.0471)\t Accuracy 1.000 (0.985)\n","Epoch: [18][25/38]\t Loss 0.1298 (0.0503)\t Accuracy 0.952 (0.983)\n","Epoch: [18][26/38]\t Loss 0.0393 (0.0499)\t Accuracy 0.984 (0.983)\n","Epoch: [18][27/38]\t Loss 0.0094 (0.0485)\t Accuracy 1.000 (0.984)\n","Epoch: [18][28/38]\t Loss 0.0187 (0.0474)\t Accuracy 1.000 (0.984)\n","Epoch: [18][29/38]\t Loss 0.0364 (0.0471)\t Accuracy 0.984 (0.984)\n","Epoch: [18][30/38]\t Loss 0.1022 (0.0489)\t Accuracy 0.952 (0.983)\n","Epoch: [18][31/38]\t Loss 0.0498 (0.0489)\t Accuracy 1.000 (0.984)\n","Epoch: [18][32/38]\t Loss 0.2285 (0.0544)\t Accuracy 0.937 (0.982)\n","Epoch: [18][33/38]\t Loss 0.1383 (0.0569)\t Accuracy 0.968 (0.982)\n","Epoch: [18][34/38]\t Loss 0.1391 (0.0593)\t Accuracy 0.969 (0.982)\n","Epoch: [18][35/38]\t Loss 0.0182 (0.0582)\t Accuracy 1.000 (0.982)\n","Epoch: [18][36/38]\t Loss 0.0013 (0.0566)\t Accuracy 1.000 (0.983)\n","Epoch: [18][37/38]\t Loss 0.1922 (0.0568)\t Accuracy 1.000 (0.983)\n","Epoch: [18]\t Avg Loss 0.0568\t Avg Accuracy 0.983\n","Test Average Accuracy: 0.7800\n","Epoch: [19][0/38]\t Loss 0.0215 (0.0215)\t Accuracy 1.000 (1.000)\n","Epoch: [19][1/38]\t Loss 0.0999 (0.0614)\t Accuracy 0.952 (0.976)\n","Epoch: [19][2/38]\t Loss 0.0716 (0.0647)\t Accuracy 0.967 (0.973)\n","Epoch: [19][3/38]\t Loss 0.0196 (0.0533)\t Accuracy 1.000 (0.980)\n","Epoch: [19][4/38]\t Loss 0.0084 (0.0442)\t Accuracy 1.000 (0.984)\n","Epoch: [19][5/38]\t Loss 0.0037 (0.0373)\t Accuracy 1.000 (0.987)\n","Epoch: [19][6/38]\t Loss 0.0168 (0.0343)\t Accuracy 1.000 (0.989)\n","Epoch: [19][7/38]\t Loss 0.0332 (0.0342)\t Accuracy 0.984 (0.988)\n","Epoch: [19][8/38]\t Loss 0.0879 (0.0402)\t Accuracy 0.952 (0.984)\n","Epoch: [19][9/38]\t Loss 0.0504 (0.0412)\t Accuracy 0.984 (0.984)\n","Epoch: [19][10/38]\t Loss 0.0480 (0.0419)\t Accuracy 0.968 (0.982)\n","Epoch: [19][11/38]\t Loss 0.0095 (0.0391)\t Accuracy 1.000 (0.984)\n","Epoch: [19][12/38]\t Loss 0.1609 (0.0486)\t Accuracy 0.952 (0.982)\n","Epoch: [19][13/38]\t Loss 0.0537 (0.0490)\t Accuracy 0.984 (0.982)\n","Epoch: [19][14/38]\t Loss 0.1552 (0.0561)\t Accuracy 0.921 (0.978)\n","Epoch: [19][15/38]\t Loss 0.1583 (0.0624)\t Accuracy 0.967 (0.977)\n","Epoch: [19][16/38]\t Loss 0.1260 (0.0662)\t Accuracy 0.953 (0.975)\n","Epoch: [19][17/38]\t Loss 0.0180 (0.0635)\t Accuracy 1.000 (0.977)\n","Epoch: [19][18/38]\t Loss 0.0231 (0.0613)\t Accuracy 0.984 (0.977)\n","Epoch: [19][19/38]\t Loss 0.0435 (0.0604)\t Accuracy 0.984 (0.978)\n","Epoch: [19][20/38]\t Loss 0.1465 (0.0646)\t Accuracy 0.952 (0.976)\n","Epoch: [19][21/38]\t Loss 0.0456 (0.0637)\t Accuracy 0.968 (0.976)\n","Epoch: [19][22/38]\t Loss 0.1116 (0.0658)\t Accuracy 0.968 (0.976)\n","Epoch: [19][23/38]\t Loss 0.2219 (0.0723)\t Accuracy 0.952 (0.975)\n","Epoch: [19][24/38]\t Loss 0.0451 (0.0712)\t Accuracy 0.966 (0.974)\n","Epoch: [19][25/38]\t Loss 0.0314 (0.0697)\t Accuracy 1.000 (0.975)\n","Epoch: [19][26/38]\t Loss 0.0699 (0.0697)\t Accuracy 0.952 (0.974)\n","Epoch: [19][27/38]\t Loss 0.1048 (0.0710)\t Accuracy 0.968 (0.974)\n","Epoch: [19][28/38]\t Loss 0.0264 (0.0694)\t Accuracy 0.984 (0.975)\n","Epoch: [19][29/38]\t Loss 0.0058 (0.0673)\t Accuracy 1.000 (0.975)\n","Epoch: [19][30/38]\t Loss 0.0640 (0.0672)\t Accuracy 0.984 (0.976)\n","Epoch: [19][31/38]\t Loss 0.3697 (0.0768)\t Accuracy 0.921 (0.974)\n","Epoch: [19][32/38]\t Loss 0.1452 (0.0788)\t Accuracy 0.951 (0.973)\n","Epoch: [19][33/38]\t Loss 0.0320 (0.0774)\t Accuracy 0.984 (0.974)\n","Epoch: [19][34/38]\t Loss 0.0228 (0.0758)\t Accuracy 0.984 (0.974)\n","Epoch: [19][35/38]\t Loss 0.0013 (0.0738)\t Accuracy 1.000 (0.975)\n","Epoch: [19][36/38]\t Loss 0.0707 (0.0737)\t Accuracy 0.967 (0.974)\n","Epoch: [19][37/38]\t Loss 0.0002 (0.0735)\t Accuracy 1.000 (0.974)\n","Epoch: [19]\t Avg Loss 0.0735\t Avg Accuracy 0.974\n","Test Average Accuracy: 0.7899\n","Epoch: [20][0/38]\t Loss 0.0287 (0.0287)\t Accuracy 0.984 (0.984)\n","Epoch: [20][1/38]\t Loss 0.0604 (0.0444)\t Accuracy 0.968 (0.976)\n","Epoch: [20][2/38]\t Loss 0.0192 (0.0359)\t Accuracy 1.000 (0.984)\n","Epoch: [20][3/38]\t Loss 0.0756 (0.0458)\t Accuracy 0.984 (0.984)\n","Epoch: [20][4/38]\t Loss 0.0580 (0.0483)\t Accuracy 0.984 (0.984)\n","Epoch: [20][5/38]\t Loss 0.0159 (0.0429)\t Accuracy 1.000 (0.987)\n","Epoch: [20][6/38]\t Loss 0.0060 (0.0377)\t Accuracy 1.000 (0.989)\n","Epoch: [20][7/38]\t Loss 0.0177 (0.0353)\t Accuracy 1.000 (0.990)\n","Epoch: [20][8/38]\t Loss 0.0088 (0.0324)\t Accuracy 1.000 (0.991)\n","Epoch: [20][9/38]\t Loss 0.0101 (0.0301)\t Accuracy 1.000 (0.992)\n","Epoch: [20][10/38]\t Loss 0.0207 (0.0293)\t Accuracy 1.000 (0.993)\n","Epoch: [20][11/38]\t Loss 0.1629 (0.0404)\t Accuracy 0.952 (0.989)\n","Epoch: [20][12/38]\t Loss 0.0681 (0.0425)\t Accuracy 0.967 (0.988)\n","Epoch: [20][13/38]\t Loss 0.0292 (0.0415)\t Accuracy 0.984 (0.987)\n","Epoch: [20][14/38]\t Loss 0.0057 (0.0391)\t Accuracy 1.000 (0.988)\n","Epoch: [20][15/38]\t Loss 0.0347 (0.0388)\t Accuracy 0.984 (0.988)\n","Epoch: [20][16/38]\t Loss 0.0137 (0.0373)\t Accuracy 0.984 (0.988)\n","Epoch: [20][17/38]\t Loss 0.0123 (0.0359)\t Accuracy 1.000 (0.988)\n","Epoch: [20][18/38]\t Loss 0.0521 (0.0368)\t Accuracy 0.984 (0.988)\n","Epoch: [20][19/38]\t Loss 0.0873 (0.0391)\t Accuracy 0.947 (0.986)\n","Epoch: [20][20/38]\t Loss 0.0288 (0.0386)\t Accuracy 0.983 (0.986)\n","Epoch: [20][21/38]\t Loss 0.0071 (0.0372)\t Accuracy 1.000 (0.987)\n","Epoch: [20][22/38]\t Loss 0.2778 (0.0478)\t Accuracy 0.937 (0.985)\n","Epoch: [20][23/38]\t Loss 0.2121 (0.0546)\t Accuracy 0.935 (0.983)\n","Epoch: [20][24/38]\t Loss 0.0337 (0.0538)\t Accuracy 0.969 (0.982)\n","Epoch: [20][25/38]\t Loss 0.0079 (0.0520)\t Accuracy 1.000 (0.983)\n","Epoch: [20][26/38]\t Loss 0.0274 (0.0510)\t Accuracy 0.984 (0.983)\n","Epoch: [20][27/38]\t Loss 0.0187 (0.0499)\t Accuracy 0.984 (0.983)\n","Epoch: [20][28/38]\t Loss 0.0421 (0.0496)\t Accuracy 0.984 (0.983)\n","Epoch: [20][29/38]\t Loss 0.0661 (0.0501)\t Accuracy 0.952 (0.982)\n","Epoch: [20][30/38]\t Loss 0.0340 (0.0496)\t Accuracy 1.000 (0.982)\n","Epoch: [20][31/38]\t Loss 0.0438 (0.0494)\t Accuracy 0.984 (0.982)\n","Epoch: [20][32/38]\t Loss 0.0022 (0.0480)\t Accuracy 1.000 (0.983)\n","Epoch: [20][33/38]\t Loss 0.1189 (0.0501)\t Accuracy 0.984 (0.983)\n","Epoch: [20][34/38]\t Loss 0.0828 (0.0510)\t Accuracy 0.968 (0.983)\n","Epoch: [20][35/38]\t Loss 0.0441 (0.0509)\t Accuracy 0.984 (0.983)\n","Epoch: [20][36/38]\t Loss 0.0432 (0.0507)\t Accuracy 0.967 (0.982)\n","Epoch: [20][37/38]\t Loss 0.0001 (0.0505)\t Accuracy 1.000 (0.982)\n","Epoch: [20]\t Avg Loss 0.0505\t Avg Accuracy 0.982\n","Test Average Accuracy: 0.7708\n","Epoch: [21][0/38]\t Loss 0.1089 (0.1089)\t Accuracy 0.968 (0.968)\n","Epoch: [21][1/38]\t Loss 0.0740 (0.0917)\t Accuracy 0.967 (0.968)\n","Epoch: [21][2/38]\t Loss 0.0370 (0.0737)\t Accuracy 1.000 (0.978)\n","Epoch: [21][3/38]\t Loss 0.0316 (0.0632)\t Accuracy 0.984 (0.980)\n","Epoch: [21][4/38]\t Loss 0.0124 (0.0527)\t Accuracy 1.000 (0.984)\n","Epoch: [21][5/38]\t Loss 0.0210 (0.0474)\t Accuracy 0.984 (0.984)\n","Epoch: [21][6/38]\t Loss 0.0564 (0.0487)\t Accuracy 0.984 (0.984)\n","Epoch: [21][7/38]\t Loss 0.0659 (0.0509)\t Accuracy 0.984 (0.984)\n","Epoch: [21][8/38]\t Loss 0.0311 (0.0486)\t Accuracy 0.984 (0.984)\n","Epoch: [21][9/38]\t Loss 0.0161 (0.0454)\t Accuracy 1.000 (0.986)\n","Epoch: [21][10/38]\t Loss 0.1344 (0.0535)\t Accuracy 0.935 (0.981)\n","Epoch: [21][11/38]\t Loss 0.0688 (0.0547)\t Accuracy 0.984 (0.981)\n","Epoch: [21][12/38]\t Loss 0.1476 (0.0616)\t Accuracy 0.983 (0.981)\n","Epoch: [21][13/38]\t Loss 0.2107 (0.0726)\t Accuracy 0.922 (0.977)\n","Epoch: [21][14/38]\t Loss 0.0425 (0.0706)\t Accuracy 0.968 (0.976)\n","Epoch: [21][15/38]\t Loss 0.0862 (0.0716)\t Accuracy 0.953 (0.975)\n","Epoch: [21][16/38]\t Loss 0.0489 (0.0702)\t Accuracy 0.984 (0.975)\n","Epoch: [21][17/38]\t Loss 0.0124 (0.0669)\t Accuracy 1.000 (0.977)\n","Epoch: [21][18/38]\t Loss 0.0720 (0.0672)\t Accuracy 0.984 (0.977)\n","Epoch: [21][19/38]\t Loss 0.0107 (0.0643)\t Accuracy 1.000 (0.978)\n","Epoch: [21][20/38]\t Loss 0.0593 (0.0641)\t Accuracy 0.969 (0.978)\n","Epoch: [21][21/38]\t Loss 0.0322 (0.0626)\t Accuracy 0.968 (0.977)\n","Epoch: [21][22/38]\t Loss 0.0535 (0.0622)\t Accuracy 0.968 (0.977)\n","Epoch: [21][23/38]\t Loss 0.0315 (0.0609)\t Accuracy 0.984 (0.977)\n","Epoch: [21][24/38]\t Loss 0.0507 (0.0605)\t Accuracy 0.984 (0.978)\n","Epoch: [21][25/38]\t Loss 0.0047 (0.0584)\t Accuracy 1.000 (0.979)\n","Epoch: [21][26/38]\t Loss 0.0791 (0.0591)\t Accuracy 0.984 (0.979)\n","Epoch: [21][27/38]\t Loss 0.0135 (0.0576)\t Accuracy 1.000 (0.979)\n","Epoch: [21][28/38]\t Loss 0.0242 (0.0565)\t Accuracy 0.983 (0.980)\n","Epoch: [21][29/38]\t Loss 0.1112 (0.0583)\t Accuracy 0.968 (0.979)\n","Epoch: [21][30/38]\t Loss 0.0473 (0.0579)\t Accuracy 0.984 (0.979)\n","Epoch: [21][31/38]\t Loss 0.0403 (0.0574)\t Accuracy 0.967 (0.979)\n","Epoch: [21][32/38]\t Loss 0.0452 (0.0570)\t Accuracy 0.984 (0.979)\n","Epoch: [21][33/38]\t Loss 0.0014 (0.0554)\t Accuracy 1.000 (0.980)\n","Epoch: [21][34/38]\t Loss 0.0161 (0.0543)\t Accuracy 1.000 (0.980)\n","Epoch: [21][35/38]\t Loss 0.0020 (0.0528)\t Accuracy 1.000 (0.981)\n","Epoch: [21][36/38]\t Loss 0.0891 (0.0538)\t Accuracy 0.951 (0.980)\n","Epoch: [21][37/38]\t Loss 0.0162 (0.0537)\t Accuracy 1.000 (0.980)\n","Epoch: [21]\t Avg Loss 0.0537\t Avg Accuracy 0.980\n","Test Average Accuracy: 0.7833\n","Epoch: [22][0/38]\t Loss 0.0397 (0.0397)\t Accuracy 0.984 (0.984)\n","Epoch: [22][1/38]\t Loss 0.0493 (0.0445)\t Accuracy 0.984 (0.984)\n","Epoch: [22][2/38]\t Loss 0.0065 (0.0316)\t Accuracy 1.000 (0.989)\n","Epoch: [22][3/38]\t Loss 0.0352 (0.0325)\t Accuracy 0.984 (0.988)\n","Epoch: [22][4/38]\t Loss 0.0236 (0.0307)\t Accuracy 0.984 (0.987)\n","Epoch: [22][5/38]\t Loss 0.0661 (0.0365)\t Accuracy 0.951 (0.981)\n","Epoch: [22][6/38]\t Loss 0.0029 (0.0318)\t Accuracy 1.000 (0.984)\n","Epoch: [22][7/38]\t Loss 0.0092 (0.0290)\t Accuracy 1.000 (0.986)\n","Epoch: [22][8/38]\t Loss 0.0600 (0.0324)\t Accuracy 0.984 (0.986)\n","Epoch: [22][9/38]\t Loss 0.1272 (0.0420)\t Accuracy 0.968 (0.984)\n","Epoch: [22][10/38]\t Loss 0.0020 (0.0384)\t Accuracy 1.000 (0.985)\n","Epoch: [22][11/38]\t Loss 0.0201 (0.0368)\t Accuracy 0.984 (0.985)\n","Epoch: [22][12/38]\t Loss 0.1677 (0.0467)\t Accuracy 0.967 (0.984)\n","Epoch: [22][13/38]\t Loss 0.1003 (0.0506)\t Accuracy 0.953 (0.982)\n","Epoch: [22][14/38]\t Loss 0.0842 (0.0528)\t Accuracy 0.952 (0.980)\n","Epoch: [22][15/38]\t Loss 0.0255 (0.0511)\t Accuracy 0.984 (0.980)\n","Epoch: [22][16/38]\t Loss 0.0810 (0.0529)\t Accuracy 0.968 (0.979)\n","Epoch: [22][17/38]\t Loss 0.0650 (0.0535)\t Accuracy 0.968 (0.979)\n","Epoch: [22][18/38]\t Loss 0.0012 (0.0509)\t Accuracy 1.000 (0.980)\n","Epoch: [22][19/38]\t Loss 0.0279 (0.0498)\t Accuracy 0.984 (0.980)\n","Epoch: [22][20/38]\t Loss 0.0226 (0.0485)\t Accuracy 0.984 (0.980)\n","Epoch: [22][21/38]\t Loss 0.0485 (0.0485)\t Accuracy 0.967 (0.980)\n","Epoch: [22][22/38]\t Loss 0.1164 (0.0515)\t Accuracy 0.968 (0.979)\n","Epoch: [22][23/38]\t Loss 0.1660 (0.0562)\t Accuracy 0.952 (0.978)\n","Epoch: [22][24/38]\t Loss 0.0353 (0.0554)\t Accuracy 0.984 (0.978)\n","Epoch: [22][25/38]\t Loss 0.0377 (0.0547)\t Accuracy 0.984 (0.978)\n","Epoch: [22][26/38]\t Loss 0.0835 (0.0558)\t Accuracy 0.969 (0.978)\n","Epoch: [22][27/38]\t Loss 0.0301 (0.0549)\t Accuracy 0.984 (0.978)\n","Epoch: [22][28/38]\t Loss 0.0018 (0.0531)\t Accuracy 1.000 (0.979)\n","Epoch: [22][29/38]\t Loss 0.0552 (0.0532)\t Accuracy 0.969 (0.979)\n","Epoch: [22][30/38]\t Loss 0.0537 (0.0532)\t Accuracy 0.984 (0.979)\n","Epoch: [22][31/38]\t Loss 0.1085 (0.0549)\t Accuracy 0.984 (0.979)\n","Epoch: [22][32/38]\t Loss 0.0108 (0.0536)\t Accuracy 1.000 (0.980)\n","Epoch: [22][33/38]\t Loss 0.0429 (0.0533)\t Accuracy 0.967 (0.979)\n","Epoch: [22][34/38]\t Loss 0.0734 (0.0539)\t Accuracy 0.967 (0.979)\n","Epoch: [22][35/38]\t Loss 0.0258 (0.0531)\t Accuracy 0.984 (0.979)\n","Epoch: [22][36/38]\t Loss 0.0189 (0.0522)\t Accuracy 0.984 (0.979)\n","Epoch: [22][37/38]\t Loss 0.0000 (0.0520)\t Accuracy 1.000 (0.979)\n","Epoch: [22]\t Avg Loss 0.0520\t Avg Accuracy 0.979\n","Test Average Accuracy: 0.7807\n","Epoch: [23][0/38]\t Loss 0.0145 (0.0145)\t Accuracy 1.000 (1.000)\n","Epoch: [23][1/38]\t Loss 0.0367 (0.0256)\t Accuracy 0.968 (0.984)\n","Epoch: [23][2/38]\t Loss 0.1043 (0.0515)\t Accuracy 0.984 (0.984)\n","Epoch: [23][3/38]\t Loss 0.0094 (0.0411)\t Accuracy 1.000 (0.988)\n","Epoch: [23][4/38]\t Loss 0.0017 (0.0333)\t Accuracy 1.000 (0.990)\n","Epoch: [23][5/38]\t Loss 0.0046 (0.0285)\t Accuracy 1.000 (0.992)\n","Epoch: [23][6/38]\t Loss 0.0013 (0.0245)\t Accuracy 1.000 (0.993)\n","Epoch: [23][7/38]\t Loss 0.0063 (0.0222)\t Accuracy 1.000 (0.994)\n","Epoch: [23][8/38]\t Loss 0.0020 (0.0200)\t Accuracy 1.000 (0.995)\n","Epoch: [23][9/38]\t Loss 0.0813 (0.0261)\t Accuracy 0.984 (0.994)\n","Epoch: [23][10/38]\t Loss 0.0263 (0.0261)\t Accuracy 0.983 (0.993)\n","Epoch: [23][11/38]\t Loss 0.0300 (0.0264)\t Accuracy 0.984 (0.992)\n","Epoch: [23][12/38]\t Loss 0.0096 (0.0251)\t Accuracy 1.000 (0.993)\n","Epoch: [23][13/38]\t Loss 0.0370 (0.0260)\t Accuracy 0.968 (0.991)\n","Epoch: [23][14/38]\t Loss 0.0234 (0.0258)\t Accuracy 0.984 (0.990)\n","Epoch: [23][15/38]\t Loss 0.0038 (0.0244)\t Accuracy 1.000 (0.991)\n","Epoch: [23][16/38]\t Loss 0.2457 (0.0374)\t Accuracy 0.952 (0.989)\n","Epoch: [23][17/38]\t Loss 0.0691 (0.0392)\t Accuracy 0.984 (0.988)\n","Epoch: [23][18/38]\t Loss 0.0078 (0.0375)\t Accuracy 1.000 (0.989)\n","Epoch: [23][19/38]\t Loss 0.1897 (0.0453)\t Accuracy 0.953 (0.987)\n","Epoch: [23][20/38]\t Loss 0.0019 (0.0433)\t Accuracy 1.000 (0.988)\n","Epoch: [23][21/38]\t Loss 0.0680 (0.0444)\t Accuracy 0.968 (0.987)\n","Epoch: [23][22/38]\t Loss 0.0100 (0.0429)\t Accuracy 1.000 (0.987)\n","Epoch: [23][23/38]\t Loss 0.0054 (0.0414)\t Accuracy 1.000 (0.988)\n","Epoch: [23][24/38]\t Loss 0.0183 (0.0405)\t Accuracy 0.983 (0.988)\n","Epoch: [23][25/38]\t Loss 0.0238 (0.0398)\t Accuracy 0.984 (0.988)\n","Epoch: [23][26/38]\t Loss 0.0682 (0.0409)\t Accuracy 0.984 (0.987)\n","Epoch: [23][27/38]\t Loss 0.0593 (0.0416)\t Accuracy 0.984 (0.987)\n","Epoch: [23][28/38]\t Loss 0.0651 (0.0424)\t Accuracy 0.968 (0.987)\n","Epoch: [23][29/38]\t Loss 0.0070 (0.0412)\t Accuracy 1.000 (0.987)\n","Epoch: [23][30/38]\t Loss 0.0195 (0.0405)\t Accuracy 1.000 (0.988)\n","Epoch: [23][31/38]\t Loss 0.0340 (0.0403)\t Accuracy 0.984 (0.987)\n","Epoch: [23][32/38]\t Loss 0.0326 (0.0401)\t Accuracy 0.984 (0.987)\n","Epoch: [23][33/38]\t Loss 0.0036 (0.0390)\t Accuracy 1.000 (0.988)\n","Epoch: [23][34/38]\t Loss 0.0354 (0.0389)\t Accuracy 0.967 (0.987)\n","Epoch: [23][35/38]\t Loss 0.0768 (0.0400)\t Accuracy 0.969 (0.987)\n","Epoch: [23][36/38]\t Loss 0.0685 (0.0408)\t Accuracy 0.969 (0.986)\n","Epoch: [23][37/38]\t Loss 0.0000 (0.0407)\t Accuracy 1.000 (0.986)\n","Epoch: [23]\t Avg Loss 0.0407\t Avg Accuracy 0.986\n","Test Average Accuracy: 0.7886\n","Epoch: [24][0/38]\t Loss 0.0105 (0.0105)\t Accuracy 1.000 (1.000)\n","Epoch: [24][1/38]\t Loss 0.0044 (0.0075)\t Accuracy 1.000 (1.000)\n","Epoch: [24][2/38]\t Loss 0.0325 (0.0156)\t Accuracy 0.984 (0.995)\n","Epoch: [24][3/38]\t Loss 0.0034 (0.0126)\t Accuracy 1.000 (0.996)\n","Epoch: [24][4/38]\t Loss 0.1872 (0.0468)\t Accuracy 0.951 (0.987)\n","Epoch: [24][5/38]\t Loss 0.0745 (0.0514)\t Accuracy 0.968 (0.984)\n","Epoch: [24][6/38]\t Loss 0.0492 (0.0511)\t Accuracy 0.984 (0.984)\n","Epoch: [24][7/38]\t Loss 0.0012 (0.0448)\t Accuracy 1.000 (0.986)\n","Epoch: [24][8/38]\t Loss 0.0158 (0.0415)\t Accuracy 1.000 (0.988)\n","Epoch: [24][9/38]\t Loss 0.0032 (0.0378)\t Accuracy 1.000 (0.989)\n","Epoch: [24][10/38]\t Loss 0.0198 (0.0362)\t Accuracy 0.983 (0.988)\n","Epoch: [24][11/38]\t Loss 0.0018 (0.0334)\t Accuracy 1.000 (0.989)\n","Epoch: [24][12/38]\t Loss 0.0209 (0.0325)\t Accuracy 0.984 (0.989)\n","Epoch: [24][13/38]\t Loss 0.0534 (0.0339)\t Accuracy 0.984 (0.988)\n","Epoch: [24][14/38]\t Loss 0.0305 (0.0337)\t Accuracy 0.984 (0.988)\n","Epoch: [24][15/38]\t Loss 0.0224 (0.0330)\t Accuracy 0.984 (0.988)\n","Epoch: [24][16/38]\t Loss 0.0414 (0.0335)\t Accuracy 0.968 (0.987)\n","Epoch: [24][17/38]\t Loss 0.0724 (0.0356)\t Accuracy 0.967 (0.986)\n","Epoch: [24][18/38]\t Loss 0.1849 (0.0436)\t Accuracy 0.937 (0.983)\n","Epoch: [24][19/38]\t Loss 0.1766 (0.0503)\t Accuracy 0.952 (0.981)\n","Epoch: [24][20/38]\t Loss 0.0443 (0.0500)\t Accuracy 0.984 (0.982)\n","Epoch: [24][21/38]\t Loss 0.0164 (0.0485)\t Accuracy 1.000 (0.982)\n","Epoch: [24][22/38]\t Loss 0.1336 (0.0523)\t Accuracy 0.969 (0.982)\n","Epoch: [24][23/38]\t Loss 0.0008 (0.0502)\t Accuracy 1.000 (0.983)\n","Epoch: [24][24/38]\t Loss 0.0043 (0.0483)\t Accuracy 1.000 (0.983)\n","Epoch: [24][25/38]\t Loss 0.0113 (0.0469)\t Accuracy 1.000 (0.984)\n","Epoch: [24][26/38]\t Loss 0.1658 (0.0513)\t Accuracy 0.968 (0.983)\n","Epoch: [24][27/38]\t Loss 0.0636 (0.0518)\t Accuracy 0.984 (0.983)\n","Epoch: [24][28/38]\t Loss 0.0046 (0.0501)\t Accuracy 1.000 (0.984)\n","Epoch: [24][29/38]\t Loss 0.0496 (0.0501)\t Accuracy 0.984 (0.984)\n","Epoch: [24][30/38]\t Loss 0.0042 (0.0486)\t Accuracy 1.000 (0.985)\n","Epoch: [24][31/38]\t Loss 0.0020 (0.0471)\t Accuracy 1.000 (0.985)\n","Epoch: [24][32/38]\t Loss 0.0091 (0.0460)\t Accuracy 1.000 (0.985)\n","Epoch: [24][33/38]\t Loss 0.0063 (0.0449)\t Accuracy 1.000 (0.986)\n","Epoch: [24][34/38]\t Loss 0.0017 (0.0436)\t Accuracy 1.000 (0.986)\n","Epoch: [24][35/38]\t Loss 0.0007 (0.0424)\t Accuracy 1.000 (0.987)\n","Epoch: [24][36/38]\t Loss 0.0450 (0.0425)\t Accuracy 0.984 (0.987)\n","Epoch: [24][37/38]\t Loss 0.0000 (0.0424)\t Accuracy 1.000 (0.987)\n","Epoch: [24]\t Avg Loss 0.0424\t Avg Accuracy 0.987\n","Test Average Accuracy: 0.7859\n"]}],"source":["config = {\n","  \"batch_size\": 64,\n","    \"num_epochs\": 25,\n","    \"lr\": 3e-3,\n","    \"max_grad_norm\": 5.0,\n","    \"embed_dim\": 100,\n","    \"word_gru_hidden_dim\": 100,\n","    \"sent_gru_hidden_dim\": 100,\n","    \"word_gru_num_layers\": 1,\n","    \"sent_gru_num_layers\": 1,\n","    \"word_att_dim\": 200,\n","    \"sent_att_dim\": 200,\n","    \"vocab_path\": \"glove.6B.100d.txt\",\n","    \"pretrain\": True,\n","    \"freeze\": False,\n","    \"use_layer_norm\": True,\n","    \"dropout\": 0.1\n","}\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","train(config, device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
